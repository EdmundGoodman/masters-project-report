@online{0xecCodingReversingHacking2017,
  title = {Coding | {{Reversing}}: {{Hacking}} the {{CPython}} Virtual Machine to Support Bytecode Debugging},
  shorttitle = {Coding | {{Reversing}}},
  author = {{0xec}},
  date = {2017-03-16},
  url = {https://0xec.blogspot.com/2017/03/hacking-cpython-virtual-machine-to.html},
  urldate = {2025-05-17},
  organization = {Coding | Reversing},
  keywords = {debugging,pjorion,programming,python},
  file = {/Users/edjg/Zotero/storage/L42GUFUD/hacking-cpython-virtual-machine-to.html}
}

@software{0xecExtremecodersreBytecode_tracer2024,
  title = {Extremecoders-Re/Bytecode\_tracer},
  author = {{0xec} and {Dominik Moritz}},
  date = {2024-07-27T13:04:29Z},
  origdate = {2017-03-16T08:04:02Z},
  url = {https://github.com/extremecoders-re/bytecode_tracer},
  urldate = {2025-05-17},
  abstract = {Tracing execution of python bytecode},
  keywords = {debugging,python,python-2-7,reverse-engineering,tracing}
}

@inproceedings{abadiTensorFlowSystemLargeScale2016,
  title = {\{\vphantom\}{{TensorFlow}}\vphantom\{\}: {{A System}} for \{\vphantom\}{{Large-Scale}}\vphantom\{\} {{Machine Learning}}},
  shorttitle = {\{\vphantom\}{{TensorFlow}}\vphantom\{\}},
  author = {Abadi, Martin and Barham, Paul and Chen, Jianmin and Chen, Zhifeng and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Irving, Geoffrey and Isard, Michael and Kudlur, Manjunath and Levenberg, Josh and Monga, Rajat and Moore, Sherry and Murray, Derek G. and Steiner, Benoit and Tucker, Paul and Vasudevan, Vijay and Warden, Pete and Wicke, Martin and Yu, Yuan and Zheng, Xiaoqiang},
  date = {2016},
  pages = {265--283},
  url = {https://www.usenix.org/conference/osdi16/technical-sessions/presentation/abadi},
  urldate = {2024-11-12},
  eventtitle = {12th {{USENIX Symposium}} on {{Operating Systems Design}} and {{Implementation}} ({{OSDI}} 16)},
  isbn = {978-1-931971-33-1},
  langid = {english},
  file = {/Users/edjg/Zotero/storage/3XT98SWY/Abadi et al. - 2016 - TensorFlow A System for Large-Scale Machine Learning.pdf}
}

@inproceedings{akerblomMeasuringPolymorphismPython2015,
  title = {Measuring Polymorphism in Python Programs},
  booktitle = {Proceedings of the 11th {{Symposium}} on {{Dynamic Languages}}},
  author = {Åkerblom, Beatrice and Wrigstad, Tobias},
  date = {2015-10-21},
  series = {{{DLS}} 2015},
  pages = {114--128},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/2816707.2816717},
  url = {https://dl.acm.org/doi/10.1145/2816707.2816717},
  urldate = {2025-06-05},
  abstract = {Following the increased popularity of dynamic languages and their increased use in critical software, there have been many proposals to retrofit static type system to these languages to improve possibilities to catch bugs and improve performance. A key question for any type system is whether the types should be structural, for more expressiveness, or nominal, to carry more meaning for the programmer. For retrofitted type systems, it seems the current trend is using structural types. This paper attempts to answer the question to what extent this extra expressiveness is needed, and how the possible polymorphism in dynamic code is used in practise. We study polymorphism in 36 real-world open source Python programs and approximate to what extent nominal and structural types could be used to type these programs. The study is based on collecting traces from multiple runs of the programs and analysing the polymorphic degrees of targets at more than 7 million call-sites. Our results show that while polymorphism is used in all programs, the programs are to a great extent monomorphic. The polymorphism found is evenly distributed across libraries and program-specific code and occur both during program start-up and normal execution. Most programs contain a few ``megamorphic'' call-sites where receiver types vary widely. The non-monomorphic parts of the programs can to some extent be typed with nominal or structural types, but none of the approaches can type entire programs.},
  isbn = {978-1-4503-3690-1},
  file = {/Users/edjg/Zotero/storage/SPFAPMKW/Åkerblom and Wrigstad - 2015 - Measuring polymorphism in python programs.pdf}
}

@book{alfred2007compilers,
  title = {Compilers: {{Principles}}, {{Techniques}} \& {{Tools}}},
  author = {Alfred, V Aho and Monica, S Lam and Jeffrey, D Ullman},
  date = {2007},
  edition = {2},
  publisher = {pearson Education}
}

@inproceedings{amdahlValiditySingleProcessor1967,
  title = {Validity of the Single Processor Approach to Achieving Large Scale Computing Capabilities},
  booktitle = {Proceedings of the {{April}} 18-20, 1967, Spring Joint Computer Conference},
  author = {Amdahl, Gene M.},
  date = {1967-04-18},
  series = {{{AFIPS}} '67 ({{Spring}})},
  pages = {483--485},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/1465482.1465560},
  url = {https://dl.acm.org/doi/10.1145/1465482.1465560},
  urldate = {2025-01-13},
  abstract = {For over a decade prophets have voiced the contention that the organization of a single computer has reached its limits and that truly significant advances can be made only by interconnection of a multiplicity of computers in such a manner as to permit cooperative solution. Variously the proper direction has been pointed out as general purpose computers with a generalized interconnection of memories, or as specialized computers with geometrically related memory interconnections and controlled by one or more instruction streams.},
  isbn = {978-1-4503-7895-6},
  file = {/Users/edjg/Zotero/storage/VRNQ8ZCL/Amdahl - 1967 - Validity of the single processor approach to achieving large scale computing capabilities.pdf}
}

@unpublished{aminiHowSlowMLIR2024,
  title = {How {{Slow}} Is {{MLIR}}?},
  author = {Amini, Mehdi and Nui, Jeff},
  date = {2024-04},
  url = {https://www.youtube.com/watch?v=7qvVMUSxqz4},
  eventtitle = {2024 {{European LLVM Developers}}' {{Meeting}}},
  venue = {Vienna, Austria}
}

@online{appleinc.Mach_absolute_time,
  title = {Mach\_absolute\_time},
  author = {{Apple Inc.}},
  url = {https://developer.apple.com/documentation/kernel/1462446-mach_absolute_time},
  urldate = {2025-05-28},
  abstract = {Returns current value of a clock that increments monotonically in tick units (starting at an arbitrary point), this clock does not increment while the system is asleep.},
  langid = {american},
  organization = {Apple Developer Documentation},
  file = {/Users/edjg/Zotero/storage/JR5TLPBR/1462446-mach_absolute_time.html}
}

@online{armlimitedARMCortexRSeries,
  title = {{{ARM Cortex-R Series}} ({{Armv7-R}}) {{Programmer}}'s {{Guide}}},
  author = {{Arm Limited}},
  url = {https://developer.arm.com/documentation/den0042/a/Unified-Assembly-Language-Instructions/Branches/Direct-and-indirect-branches},
  urldate = {2025-06-05},
  file = {/Users/edjg/Zotero/storage/8VGRGZBA/Direct-and-indirect-branches.html}
}

@article{aycockBriefHistoryJustintime2003,
  title = {A Brief History of Just-in-Time},
  author = {Aycock, John},
  date = {2003-06-01},
  journaltitle = {ACM Comput. Surv.},
  volume = {35},
  number = {2},
  pages = {97--113},
  issn = {0360-0300},
  doi = {10.1145/857076.857077},
  url = {https://dl.acm.org/doi/10.1145/857076.857077},
  urldate = {2025-05-11},
  abstract = {Software systems have been using "just-in-time" compilation (JIT) techniques since the 1960s. Broadly, JIT compilation includes any translation performed dynamically, after a program has started execution. We examine the motivation behind JIT compilation and constraints imposed on JIT compilation systems, and present a classification scheme for such systems. This classification emerges as we survey forty years of JIT work, from 1960--2000.},
  file = {/Users/edjg/Zotero/storage/KFW9CF8P/Aycock - 2003 - A brief history of just-in-time.pdf}
}

@inproceedings{baconFastStaticAnalysis1996,
  title = {Fast Static Analysis of {{C}}++ Virtual Function Calls},
  booktitle = {Proceedings of the 11th {{ACM SIGPLAN}} Conference on {{Object-oriented}} Programming, Systems, Languages, and Applications},
  author = {Bacon, David F. and Sweeney, Peter F.},
  date = {1996-10-01},
  series = {{{OOPSLA}} '96},
  pages = {324--341},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/236337.236371},
  url = {https://dl.acm.org/doi/10.1145/236337.236371},
  urldate = {2025-05-11},
  abstract = {Virtual functions make code easier for programmers to reuse but also make it harder for compilers to analyze. We investigate the ability of three static analysis algorithms to improve C++ programs by resolving virtual function calls, thereby reducing compiled code size and reducing program complexity so as to improve both human and automated program understanding and analysis. In measurements of seven programs of significant size (5000 to 20000 lines of code each) we found that on average the most precise of the three algorithms resolved 71\% of the virtual function calls and reduced compiled code size by 25\%. This algorithm is very fast: it analyzes 3300 source lines per second on an 80 MHz PowerPC 601. Because of its accuracy and speed, this algorithm is an excellent candidate for inclusion in production C++ compilers.},
  isbn = {978-0-89791-788-9},
  file = {/Users/edjg/Zotero/storage/LL8LCXSD/Bacon and Sweeney - 1996 - Fast static analysis of C++ virtual function calls.pdf}
}

@article{barrettVirtualMachineWarmup2017,
  title = {Virtual {{Machine Warmup Blows Hot}} and {{Cold}}},
  author = {Barrett, Edd and Bolz-Tereick, Carl Friedrich and Killick, Rebecca and Mount, Sarah and Tratt, Laurence},
  date = {2017-10-12},
  journaltitle = {Proceedings of the ACM on Programming Languages},
  shortjournal = {Proc. ACM Program. Lang.},
  volume = {1},
  eprint = {1602.00602},
  eprinttype = {arXiv},
  eprintclass = {cs},
  pages = {1--27},
  issn = {2475-1421},
  doi = {10.1145/3133876},
  url = {http://arxiv.org/abs/1602.00602},
  urldate = {2025-05-14},
  abstract = {Virtual Machines (VMs) with Just-In-Time (JIT) compilers are traditionally thought to execute programs in two phases: the initial warmup phase determines which parts of a program would most benefit from dynamic compilation, before JIT compiling those parts into machine code; subsequently the program is said to be at a steady state of peak performance. Measurement methodologies almost always discard data collected during the warmup phase such that reported measurements focus entirely on peak performance. We introduce a fully automated statistical approach, based on changepoint analysis, which allows us to determine if a program has reached a steady state and, if so, whether that represents peak performance or not. Using this, we show that even when run in the most controlled of circumstances, small, deterministic, widely studied microbenchmarks often fail to reach a steady state of peak performance on a variety of common VMs. Repeating our experiment on 3 different machines, we found that at most 43.5\% of {$<$}VM, benchmark{$>$} pairs consistently reach a steady state of peak performance.},
  issue = {OOPSLA},
  keywords = {Computer Science - Programming Languages},
  file = {/Users/edjg/Zotero/storage/MR6M8M8V/Barrett et al. - 2017 - Virtual Machine Warmup Blows Hot and Cold.pdf;/Users/edjg/Zotero/storage/U9VBGS8S/1602.html}
}

@online{bastienabadieEngineeringCodeQuality,
  title = {Engineering Code Quality in the {{Firefox}} Browser: {{A}} Look at Our Tools and Challenges},
  shorttitle = {Engineering Code Quality in the {{Firefox}} Browser},
  author = {{Bastien Abadie} and {Sylvestre Ledru}},
  url = {https://hacks.mozilla.org/2020/04/code-quality-tools-at-mozilla},
  urldate = {2025-05-13},
  abstract = {Here's an insider's look at Firefox's code quality toolchain that's been designed to manage the ongoing development and monthly releases of our desktop browser. This post explores the architecture, challenges, ...},
  langid = {american},
  organization = {Mozilla Hacks – the Web developer blog},
  file = {/Users/edjg/Zotero/storage/PS3AQWI2/code-quality-tools-at-mozilla.html}
}

@inproceedings{bergerTriangulatingPythonPerformance2023a,
  title = {Triangulating {{Python Performance Issues}} with {{SCALENE}}},
  author = {Berger, Emery D. and Stern, Sam and Pizzorno, Juan Altmayer},
  date = {2023},
  pages = {51--64},
  url = {https://www.usenix.org/conference/osdi23/presentation/berger},
  urldate = {2025-05-14},
  eventtitle = {17th {{USENIX Symposium}} on {{Operating Systems Design}} and {{Implementation}} ({{OSDI}} 23)},
  isbn = {978-1-939133-34-2},
  langid = {english},
  file = {/Users/edjg/Zotero/storage/2PSMWKHJ/Berger et al. - 2023 - Triangulating Python Performance Issues with SCALENE .pdf}
}

@article{blackburnMythsRealitiesPerformance2004,
  title = {Myths and Realities: The Performance Impact of Garbage Collection},
  shorttitle = {Myths and Realities},
  author = {Blackburn, Stephen M. and Cheng, Perry and McKinley, Kathryn S.},
  date = {2004-06-01},
  journaltitle = {SIGMETRICS Perform. Eval. Rev.},
  volume = {32},
  number = {1},
  pages = {25--36},
  issn = {0163-5999},
  doi = {10.1145/1012888.1005693},
  url = {https://dl.acm.org/doi/10.1145/1012888.1005693},
  urldate = {2025-06-10},
  abstract = {This paper explores and quantifies garbage collection behavior for three whole heap collectors and generational counterparts: copying semi-space, mark-sweep, and reference counting, the canonical algorithms from which essentially all other collection algorithms are derived. Efficient implementations in MMTk, a Java memory management toolkit, in IBM's Jikes RVM share all common mechanisms to provide a clean experimental platform. Instrumentation separates collector and program behavior, and performance counters measure timing and memory behavior on three architectures.Our experimental design reveals key algorithmic features and how they match program characteristics to explain the direct and indirect costs of garbage collection as a function of heap size on the SPEC JVM benchmarks. For example, we find that the contiguous allocation of copying collectors attains significant locality benefits over free-list allocators. The reduced collection costs of the generational algorithms together with the locality benefit of contiguous allocation motivates a copying nursery for newly allocated objects. These benefits dominate the overheads of generational collectors compared with non-generational and no collection, disputing the myth that "no garbage collection is good garbage collection." Performance is less sensitive to the mature space collection algorithm in our benchmarks. However the locality and pointer mutation characteristics for a given program occasionally prefer copying or mark-sweep. This study is unique in its breadth of garbage collection algorithms and its depth of analysis.},
  file = {/Users/edjg/Zotero/storage/ZET69QNH/Blackburn et al. - 2004 - Myths and realities the performance impact of garbage collection.pdf}
}

@article{bloomCriteriaEvaluatingPerformance,
  title = {Criteria for {{Evaluating}} the {{Performance}} of {{Compilers}}},
  author = {Bloom, Burton H and Clark, Mac H and Feldman, Clare G and Coe, Robert K},
  langid = {english},
  file = {/Users/edjg/Zotero/storage/ADRFPYNM/Bloom et al. - Criteria for Evaluating the Performance of Compilers.pdf}
}

@inproceedings{brueningInfrastructureAdaptiveDynamic2003,
  title = {An Infrastructure for Adaptive Dynamic Optimization},
  booktitle = {International {{Symposium}} on {{Code Generation}} and {{Optimization}}, 2003. {{CGO}} 2003.},
  author = {Bruening, D. and Garnett, T. and Amarasinghe, S.},
  date = {2003-03},
  pages = {265--275},
  doi = {10.1109/CGO.2003.1191551},
  url = {https://ieeexplore.ieee.org/abstract/document/1191551},
  urldate = {2025-06-06},
  abstract = {Dynamic optimization is emerging as a promising approach to overcome many of the obstacles of traditional static compilation. But while there are a number of compiler infrastructures for developing static optimizations, there are very few for developing dynamic optimizations. We present a framework for implementing dynamic analyses and optimizations. We provide an interface for building external modules, or clients, for the DynamoRIO dynamic code modification system. This interface abstracts away many low-level details of the DynamoRIO runtime system while exposing a simple and powerful, yet efficient and lightweight API. This is achieved by restricting optimization units to linear streams of code and using adaptive levels of detail for representing instructions. The interface is not restricted to optimization and can be used for instrumentation, profiling, dynamic translation, etc. To demonstrate the usefulness and effectiveness of our framework, we implemented several optimizations. These improve the performance of some applications by as much as 40\% relative to native execution. The average speedup relative to base DynamoRIO performance is 12\%.},
  eventtitle = {International {{Symposium}} on {{Code Generation}} and {{Optimization}}, 2003. {{CGO}} 2003.},
  keywords = {Abstracts,Application software,Computer science,Instruments,Laboratories,Optimizing compilers,Performance analysis,Runtime,Software libraries,Software performance},
  file = {/Users/edjg/Zotero/storage/2TK9SA4U/Bruening et al. - 2003 - An infrastructure for adaptive dynamic optimization.pdf}
}

@online{bytecodeallianceCranelift,
  title = {Cranelift},
  author = {{Bytecode Alliance}},
  url = {https://cranelift.dev/},
  urldate = {2025-06-10},
  file = {/Users/edjg/Zotero/storage/X4USSXTW/cranelift.dev.html}
}

@inproceedings{callahanInterproceduralConstantPropagation1986,
  title = {Interprocedural Constant Propagation},
  booktitle = {Proceedings of the 1986 {{SIGPLAN}} Symposium on {{Compiler}} Construction},
  author = {Callahan, David and Cooper, Keith D. and Kennedy, Ken and Torczon, Linda},
  date = {1986-07-01},
  series = {{{SIGPLAN}} '86},
  pages = {152--161},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/12276.13327},
  url = {https://dl.acm.org/doi/10.1145/12276.13327},
  urldate = {2025-05-16},
  abstract = {In a compiling system that attempts to improve code for a whole program by optimizing across procedures, the compiler can generate better code for a specific procedure if it knows which variables will have constant values, and what those values will be, when the procedure is invoked. This paper presents a general algorithm for determining for each procedure in a given program the set of inputs that will have known constant values at run time. The precision of the answers provided by this method are dependent on the precision of the local analysis of individual procedures in the program. Since the algorithm is intended for use in a sophisticated software development environment in which local analysis would be provided by the source editor, the quality of the answers will depend on the amount of work the editor performs. Several reasonable strategies for local analysis with different levels of complexity and precision are suggested and the results of a prototype implementation in a vectorizing Fortran compiler are presented.},
  isbn = {978-0-89791-197-9},
  file = {/Users/edjg/Zotero/storage/N39QA3AE/Callahan et al. - 1986 - Interprocedural constant propagation.pdf}
}

@incollection{chatleyNext7000Programming2019,
  title = {The {{Next}} 7000 {{Programming Languages}}},
  booktitle = {Computing and {{Software Science}}: {{State}} of the {{Art}} and {{Perspectives}}},
  author = {Chatley, Robert and Donaldson, Alastair and Mycroft, Alan},
  editor = {Steffen, Bernhard and Woeginger, Gerhard},
  date = {2019},
  pages = {250--282},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-319-91908-9_15},
  url = {https://doi.org/10.1007/978-3-319-91908-9_15},
  urldate = {2025-05-10},
  abstract = {Landin’s seminal paper “The next 700 programming languages” considered programming languages prior to 1966 and speculated on the next 700. Half-a-century on, we cast programming languages in a Darwinian ‘tree of life’ and explore languages, their features (genes) and language evolution from the viewpoint of ‘survival of the fittest’.},
  isbn = {978-3-319-91908-9},
  langid = {english},
  file = {/Users/edjg/Zotero/storage/8ZWWCKTL/Chatley et al. - 2019 - The Next 7000 Programming Languages.pdf}
}

@online{clementrouaultUnderstandingPythonExecution,
  title = {Understanding {{Python}} Execution from inside: {{A Python}} Assembly Tracer - {{Hakril}}'s Blog},
  author = {{Clement Rouault}},
  url = {https://blog.hakril.net/articles/2-understanding-python-execution-tracer.html},
  urldate = {2025-05-17},
  file = {/Users/edjg/Zotero/storage/Q3ISCLWL/2-understanding-python-execution-tracer.html}
}

@software{collinwinterPythonPyperformance2025,
  title = {Python/Pyperformance},
  author = {{Collin Winter} and {Jeffrey Yasskin}},
  date = {2025-05-06T16:31:43Z},
  origdate = {2016-08-17T23:43:22Z},
  url = {https://github.com/python/pyperformance},
  urldate = {2025-05-15},
  abstract = {Python Performance Benchmark Suite},
  organization = {Python},
  keywords = {benchmark,performance,python}
}

@article{cooperAdaptiveOptimizingCompilers2002,
  title = {Adaptive {{Optimizing Compilers}} for the 21st {{Century}}},
  author = {Cooper, Keith D. and Subramanian, Devika and Torczon, Linda},
  date = {2002-08-01},
  journaltitle = {The Journal of Supercomputing},
  shortjournal = {The Journal of Supercomputing},
  volume = {23},
  number = {1},
  pages = {7--22},
  issn = {1573-0484},
  doi = {10.1023/A:1015729001611},
  url = {https://doi.org/10.1023/A:1015729001611},
  urldate = {2025-05-12},
  abstract = {Historically, compilers have operated by applying a fixed set of optimizations in a predetermined order. We call such an ordered list of optimizations a compilation sequence. This paper describes a prototype system that uses biased random search to discover a program-specific compilation sequence that minimizes an explicit, external objective function. The result is a compiler framework that adapts its behavior to the application being compiled, to the pool of available transformations, to the objective function, and to the target machine.},
  langid = {english},
  keywords = {biased random search,configurable compilers,optimizing compilers,order of optimization},
  file = {/Users/edjg/Zotero/storage/YHJIJZQ4/Cooper et al. - 2002 - Adaptive Optimizing Compilers for the 21st Century.pdf}
}

@thesis{crapeperformance,
  type = {Master's dissertation},
  title = {Performance Analysis and Benchmarking of {{Python}}},
  author = {Crapé, Arthur},
  date = {2020},
  institution = {Ghent University},
  location = {Ghent, Belgium},
  pagetotal = {105},
  file = {/Users/edjg/Zotero/storage/W2EIY5QW/Crapé - Performance analysis and benchmarking of python.pdf}
}

@article{curtsingerSTABILIZERStatisticallySound2013,
  title = {{{STABILIZER}}: Statistically Sound Performance Evaluation},
  shorttitle = {{{STABILIZER}}},
  author = {Curtsinger, Charlie and Berger, Emery D.},
  date = {2013-03-16},
  journaltitle = {SIGARCH Comput. Archit. News},
  volume = {41},
  number = {1},
  pages = {219--228},
  issn = {0163-5964},
  doi = {10.1145/2490301.2451141},
  url = {https://dl.acm.org/doi/10.1145/2490301.2451141},
  urldate = {2025-01-29},
  abstract = {Researchers and software developers require effective performance evaluation. Researchers must evaluate optimizations or measure overhead. Software developers use automatic performance regression tests to discover when changes improve or degrade performance. The standard methodology is to compare execution times before and after applying changes.Unfortunately, modern architectural features make this approach unsound. Statistically sound evaluation requires multiple samples to test whether one can or cannot (with high confidence) reject the null hypothesis that results are the same before and after. However, caches and branch predictors make performance dependent on machine-specific parameters and the exact layout of code, stack frames, and heap objects. A single binary constitutes just one sample from the space of program layouts, regardless of the number of runs. Since compiler optimizations and code changes also alter layout, it is currently impossible to distinguish the impact of an optimization from that of its layout effects.This paper presents Stabilizer, a system that enables the use of the powerful statistical techniques required for sound performance evaluation on modern architectures. Stabilizer forces executions to sample the space of memory configurations by repeatedly re-randomizing layouts of code, stack, and heap objects at runtime. Stabilizer thus makes it possible to control for layout effects. Re-randomization also ensures that layout effects follow a Gaussian distribution, enabling the use of statistical tests like ANOVA. We demonstrate Stabilizer's efficiency (\&lt;7\% median overhead) and its effectiveness by evaluating the impact of LLVM's optimizations on the SPEC CPU2006 benchmark suite. We find that, while -O2 has a significant impact relative to -O1, the performance impact of -O3 over -O2 optimizations is indistinguishable from random noise.},
  file = {/Users/edjg/Zotero/storage/P6T7ZTT6/Curtsinger and Berger - 2013 - STABILIZER statistically sound performance evaluation.pdf}
}

@article{cytronEfficientlyComputingStatic1991,
  title = {Efficiently Computing Static Single Assignment Form and the Control Dependence Graph},
  author = {Cytron, Ron and Ferrante, Jeanne and Rosen, Barry K. and Wegman, Mark N. and Zadeck, F. Kenneth},
  date = {1991-10-01},
  journaltitle = {ACM Trans. Program. Lang. Syst.},
  volume = {13},
  number = {4},
  pages = {451--490},
  issn = {0164-0925},
  doi = {10.1145/115372.115320},
  url = {https://dl.acm.org/doi/10.1145/115372.115320},
  urldate = {2025-06-09},
  file = {/Users/edjg/Zotero/storage/NMK7KPPY/Cytron et al. - 1991 - Efficiently computing static single assignment form and the control dependence graph.pdf}
}

@online{dangohmanCanonicalization2018,
  title = {Canonicalization},
  author = {{Dan Gohman}},
  date = {2018-10-22T00:00:00+00:00},
  url = {https://sunfishcode.github.io/blog/2018/10/22/Canonicalization.html},
  urldate = {2025-05-17},
  abstract = {Canonicalization},
  langid = {american},
  organization = {sunfishcode.github.io},
  file = {/Users/edjg/Zotero/storage/PTHTQWMD/Canonicalization.html}
}

@article{desislavovTrendsAIInference2023,
  title = {Trends in {{AI}} Inference Energy Consumption: {{Beyond}} the Performance-vs-Parameter Laws of Deep Learning},
  shorttitle = {Trends in {{AI}} Inference Energy Consumption},
  author = {Desislavov, Radosvet and Martínez-Plumed, Fernando and Hernández-Orallo, José},
  date = {2023-04-01},
  journaltitle = {Sustainable Computing: Informatics and Systems},
  shortjournal = {Sustainable Computing: Informatics and Systems},
  volume = {38},
  pages = {100857},
  issn = {2210-5379},
  doi = {10.1016/j.suscom.2023.100857},
  url = {https://www.sciencedirect.com/science/article/pii/S2210537923000124},
  urldate = {2025-06-07},
  abstract = {The progress of some AI paradigms such as deep learning is said to be linked to an exponential growth in the number of parameters. There are many studies corroborating these trends, but does this translate into an exponential increase in energy consumption? In order to answer this question we focus on inference costs rather than training costs, as the former account for most of the computing effort, solely because of the multiplicative factors. Also, apart from algorithmic innovations, we account for more specific and powerful hardware (leading to higher FLOPS) that is usually accompanied with important energy efficiency optimisations. We also move the focus from the first implementation of a breakthrough paper towards the consolidated version of the techniques one or two year later. Under this distinctive and comprehensive perspective, we analyse relevant models in the areas of computer vision and natural language processing: for a sustained increase in performance we see a much softer growth in energy consumption than previously anticipated. The only caveat is, yet again, the multiplicative factor, as future AI increases penetration and becomes more pervasive.},
  keywords = {AI progress,Artificial Intelligence,Deep learning,Energy consumption,Inference,Performance analysis,Performance evaluation},
  file = {/Users/edjg/Zotero/storage/RXHCMB74/Desislavov et al. - 2023 - Trends in AI inference energy consumption Beyond the performance-vs-parameter laws of deep learning.pdf}
}

@inproceedings{drescherFastTemplateBasedCode2024,
  title = {Fast {{Template-Based Code Generation}} for {{MLIR}}},
  booktitle = {Proceedings of the 33rd {{ACM SIGPLAN International Conference}} on {{Compiler Construction}}},
  author = {Drescher, Florian and Engelke, Alexis},
  date = {2024-02-20},
  series = {{{CC}} 2024},
  pages = {1--12},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3640537.3641567},
  url = {https://dl.acm.org/doi/10.1145/3640537.3641567},
  urldate = {2025-06-10},
  abstract = {Fast compilation is essential for JIT-compilation use cases like dynamic languages or databases as well as development productivity when compiling static languages. Template-based compilation allows fast compilation times, but in existing approaches, templates are generally handwritten, limiting flexibility and causing substantial engineering effort. In this paper, we introduce an approach based on MLIR that derives code templates for the instructions of any dialect automatically ahead-of-time. Template generation re-uses the existing compilation path present in the MLIR lowering of the instructions and thereby inherently supports code generation from different abstraction levels in a single step. Our results on compiling database queries and standard C programs show a compile-time improvement of 10–30x compared to LLVM -O0 with only moderate run-time slowdowns of 1–3x, resulting in an overall improvement of 2x in a JIT-compilation-based database setting.},
  isbn = {979-8-4007-0507-6},
  file = {/Users/edjg/Zotero/storage/XLZLB3DV/Drescher and Engelke - 2024 - Fast Template-Based Code Generation for MLIR.pdf}
}

@inproceedings{driesenDirectCostVirtual1996,
  title = {The Direct Cost of Virtual Function Calls in {{C}}++},
  booktitle = {Proceedings of the 11th {{ACM SIGPLAN}} Conference on {{Object-oriented}} Programming, Systems, Languages, and Applications},
  author = {Driesen, Karel and Hölzle, Urs},
  date = {1996-10-01},
  series = {{{OOPSLA}} '96},
  pages = {306--323},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/236337.236369},
  url = {https://dl.acm.org/doi/10.1145/236337.236369},
  urldate = {2025-06-05},
  abstract = {We study the direct cost of virtual function calls in C++ programs, assuming the standard implementation using virtual function tables. We measure this overhead experimentally for a number of large benchmark programs, using a combination of executable inspection and processor simulation. Our results show that the C++ programs measured spend a median of 5.2\% of their time and 3.7\% of their instructions in dispatch code. For "all virtuals" versions of the programs, the median overhead rises to 13.7\% (13\% of the instructions). The "thunk" variant of the virtual function table implementation reduces the overhead by a median of 21\% relative to the standard implementation. On future processors, these overheads are likely to increase moderately.},
  isbn = {978-0-89791-788-9},
  file = {/Users/edjg/Zotero/storage/TMQ7HA2T/Driesen and Hölzle - 1996 - The direct cost of virtual function calls in C++.pdf}
}

@unpublished{emerybergerPythonPerformanceMatters2022,
  title = {"{{Python Performance Matters}}" by {{Emery Berger}} ({{Strange Loop}} 2022)},
  author = {{Emery Berger}},
  date = {2022-10-06},
  url = {https://www.youtube.com/watch?v=vVUnCXKuNOg},
  urldate = {2024-10-21},
  abstract = {It's 2022. Moore's Law and Dennard scaling have run out of steam, making it harder than ever to achieve high performance - especially in Python. This talk first explains in detail the unique challenges that Python poses to programmers. It then presents Scalene, a novel high-performance CPU, GPU and memory profiler for Python that does many things that past Python profilers do not and cannot do. Scalene both runs orders of magnitude faster than other profilers while delivering more accurate and more actionable information that's especially valuable to Python programmers. Emery Berger Professor, University of Massachusetts Amherst @emeryberger Emery Berger is a Professor of Computer Sciences at the University of Massachusetts Amherst, the flagship campus of the UMass system. Professor Berger and his collaborators have built numerous widely adopted software systems including Hoard, a fast and scalable memory manager that accelerates multithreaded applications (on which the Mac OS X memory manager is based); DieHard/DieHarder, error-avoiding and secure memory managers that influenced Windows, and Coz, a "causal profiler" that ships with modern Linux distros. He is also the developer and maintainer of CSrankings.org. His honors include an NSF CAREER Award, Most Influential Paper Awards at OOPSLA, at PLDI, and ASPLOS; five CACM Research Highlights, and Best Paper Awards at FAST, OOPSLA, and SOSP; he is an ACM Fellow. Professor Berger served six years as an elected member of the SIGPLAN Executive Committee; a decade as Associate Editor of TOPLAS; he was Program Chair for PLDI 2016 and co-Program Chair of ASPLOS 2021. ------- Sponsored by: ------- Stream is the \# 1 Chat API for custom messaging apps. Activate your free 30-day trial to explore Stream Chat. https://gstrm.io/tsl},
  venue = {Strange Loop Conference}
}

@inproceedings{engelkeCompileTimeAnalysisCompiler2024,
  title = {Compile-{{Time Analysis}} of {{Compiler Frameworks}} for {{Query Compilation}}},
  booktitle = {2024 {{IEEE}}/{{ACM International Symposium}} on {{Code Generation}} and {{Optimization}} ({{CGO}})},
  author = {Engelke, Alexis and Schwarz, Tobias},
  date = {2024-03},
  pages = {233--244},
  issn = {2643-2838},
  doi = {10.1109/CGO57630.2024.10444856},
  url = {https://ieeexplore.ieee.org/abstract/document/10444856},
  urldate = {2025-06-10},
  abstract = {Low compilation times are highly important in contexts of Just-in-time compilation. This not only applies to language runtimes for Java, WebAssembly, or JavaScript, but is also crucial for database systems that employ query compilation as the primary measure for achieving high throughput in combination with low query execution time. We present a performance comparison and detailed analysis of the compile times of the JIT compilation back-ends provided by GCC, LLVM, Cranelift, and a single-pass compiler in the context of database queries. Our results show that LLVM achieves the highest execution performance, but can compile substantially faster when tuning for low compilation time. Cranelift achieves a similar run-time performance to unoptimized LLVM, but compiles just 20–35\% faster and is outperformed by the single-pass compiler, which compiles code 16x faster than Cranelift at similar execution performance.},
  eventtitle = {2024 {{IEEE}}/{{ACM International Symposium}} on {{Code Generation}} and {{Optimization}} ({{CGO}})},
  keywords = {Codes,Database systems,Fast compilation,Java,JIT compilation,LLVM,Optimization,Query Compilation,Runtime,Throughput,Tuning},
  file = {/Users/edjg/Zotero/storage/3S6ZJFDH/Engelke and Schwarz - 2024 - Compile-Time Analysis of Compiler Frameworks for Query Compilation.pdf}
}

@inproceedings{engelkeInstrewLeveragingLLVM2020,
  title = {Instrew: Leveraging {{LLVM}} for High Performance Dynamic Binary Instrumentation},
  shorttitle = {Instrew},
  booktitle = {Proceedings of the 16th {{ACM SIGPLAN}}/{{SIGOPS International Conference}} on {{Virtual Execution Environments}}},
  author = {Engelke, Alexis and Schulz, Martin},
  date = {2020-03-17},
  series = {{{VEE}} '20},
  pages = {172--184},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3381052.3381319},
  url = {https://dl.acm.org/doi/10.1145/3381052.3381319},
  urldate = {2025-06-10},
  abstract = {Dynamic binary instrumentation frameworks are popular tools to enhance programs with additional analysis, debugging, or profiling facilities or to add optimizations or translations without requiring recompilation or access to source code. They analyze the binary code, translate into a---typically low-level---intermediate representation, add the needed instrumentation or transformation and then generate new code on-demand and at run-time. Most tools thereby focus on a fast code rewriting process at the cost of lower quality code, leading to a significant slowdown in the instrumented code. Further, most tools run in the application's address space, making their development cumbersome.We propose a novel dynamic binary instrumentation framework, Instrew, which closes these gaps by (a) leveraging the LLVM compiler infrastructure for high-quality code optimization and generation and (b) enables process isolation between the target code and the instrumenter. Instead of using our own non-portable and low-level intermediate representation, our framework directly lifts the original machine code into LLVM-IR, where instrumentation and behavioral changes may be performed, and from which high quality code can be produced. Results on the SPEC CPU2017 benchmarks show that the rewriting overhead is only 1/5 of the overhead incurred using the state-of-the-art toolchain Valgrind.},
  isbn = {978-1-4503-7554-2},
  file = {/Users/edjg/Zotero/storage/3W8NKCF8/Engelke and Schulz - 2020 - Instrew leveraging LLVM for high performance dynamic binary instrumentation.pdf}
}

@inproceedings{engelkeUsingLLVMOptimized2017,
  title = {Using {{LLVM}} for {{Optimized Lightweight Binary Re-Writing}} at {{Runtime}}},
  booktitle = {2017 {{IEEE International Parallel}} and {{Distributed Processing Symposium Workshops}} ({{IPDPSW}})},
  author = {Engelke, Alexis and Weidendorfer, Josef},
  date = {2017-05},
  pages = {785--794},
  doi = {10.1109/IPDPSW.2017.103},
  url = {https://ieeexplore.ieee.org/abstract/document/7965122},
  urldate = {2025-06-10},
  abstract = {Providing new parallel programming models/abstractions as a set of library functions has the huge advantage that it allows for an relatively easy incremental porting path for legacy HPC applications, in contrast to the huge effort needed when novel concepts are only provided in new programming languages or language extensions. However, performance issues are to be expected with fine granular usage of library functions. In previous work, we argued that binary rewriting can bridge the gap by tightly coupling application and library functions at runtime. We showed that runtime specialization at the binary level, starting from a compiled, generic stencil code can help in approaching performance of manually written, statically compiled version. In this paper, we analyze the benefits of post-processing the re-written binary code using standard compiler optimizations as provided by LLVM. To this end, we present our approach for efficiently converting x86-64 binary code to LLVM-IR. Using the mentioned generic code for arbitrary 2d stencils, we present performance numbers with and without LLVM postprocessing. We find that we can now achieve the performance of variants specialized by hand.},
  eventtitle = {2017 {{IEEE International Parallel}} and {{Distributed Processing Symposium Workshops}} ({{IPDPSW}})},
  keywords = {Binary codes,Binary Transformation,Decoding,Dynamic Code Generation,Dynamic Optimization,High Performance Computing,Libraries,Optimization,Registers,Runtime,Standards},
  file = {/Users/edjg/Zotero/storage/WTWXVFVX/Engelke and Weidendorfer - 2017 - Using LLVM for Optimized Lightweight Binary Re-Writing at Runtime.pdf}
}

@article{esmaeilzadehDarkSiliconEnd2012,
  title = {Dark {{Silicon}} and the {{End}} of {{Multicore Scaling}}},
  author = {Esmaeilzadeh, Hadi and Blem, Emily and St. Amant, Renee and Sankaralingam, Karthikeyan and Burger, Doug},
  date = {2012-05},
  journaltitle = {IEEE Micro},
  volume = {32},
  number = {3},
  pages = {122--134},
  issn = {1937-4143},
  doi = {10.1109/MM.2012.17},
  url = {https://ieeexplore.ieee.org/document/6175879},
  urldate = {2024-10-14},
  abstract = {A key question for the microprocessor research and design community is whether scaling multicores will provide the performance and value needed to scale down many more technology generations. To provide a quantitative answer to this question, a comprehensive study that projects the speedup potential of future multicores and examines the underutilization of integration capacity—dark silicon—is timely and crucial.},
  eventtitle = {{{IEEE Micro}}},
  keywords = {Benchmark testing,dark silicon,Microarchitecture,modeling,Moore's law,multicore,Multicore processing,Network topology,Performance evaluation,power,Silicon,technology scaling,Transistors},
  file = {/Users/edjg/Zotero/storage/VNNCFRAF/Esmaeilzadeh et al. - 2012 - Dark Silicon and the End of Multicore Scaling.pdf;/Users/edjg/Zotero/storage/DNKEE3FB/6175879.html}
}

@inproceedings{fehrIRDLIRDefinition2022a,
  title = {{{IRDL}}: An {{IR}} Definition Language for {{SSA}} Compilers},
  shorttitle = {{{IRDL}}},
  booktitle = {Proceedings of the 43rd {{ACM SIGPLAN International Conference}} on {{Programming Language Design}} and {{Implementation}}},
  author = {Fehr, Mathieu and Niu, Jeff and Riddle, River and Amini, Mehdi and Su, Zhendong and Grosser, Tobias},
  date = {2022-06-09},
  series = {{{PLDI}} 2022},
  pages = {199--212},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3519939.3523700},
  url = {https://dl.acm.org/doi/10.1145/3519939.3523700},
  urldate = {2025-04-11},
  abstract = {Designing compiler intermediate representations (IRs) is often a manual process that makes exploration and innovation in this space costly. Developers typically use general-purpose programming languages to design IRs. As a result, IR implementations are verbose, manual modifications are expensive, and designing tooling for the inspection or generation of IRs is impractical. While compilers relied historically on a few slowly evolving IRs, domain-specific optimizations and specialized hardware motivate compilers to use and evolve many IRs. We facilitate the implementation of SSA-based IRs by introducing IRDL, a domain-specific language to define IRs. We analyze all 28 domain-specific IRs developed as part of LLVM's MLIR project over the last two years and demonstrate how to express these IRs exclusively in IRDL while only rarely falling back to IRDL's support for generic C++ extensions. By enabling the concise and explicit specification of IRs, we provide foundations for developing effective tooling to automate the compiler construction process.},
  isbn = {978-1-4503-9265-5},
  file = {/Users/edjg/Zotero/storage/VB4Z3UNB/Fehr et al. - 2022 - IRDL an IR definition language for SSA compilers.pdf}
}

@software{fehrXdslprojectXdsl2024,
  title = {Xdslproject/Xdsl},
  author = {Fehr, Mathieu and Lopoukhine, Alexandre},
  date = {2024-10-21T13:01:34Z},
  origdate = {2021-09-12T14:02:30Z},
  url = {https://github.com/xdslproject/xdsl},
  urldate = {2024-10-21},
  abstract = {A Python Compiler Design Toolkit},
  organization = {xdslproject}
}

@inproceedings{fehrXDSLSidekickCompilation2025,
  title = {{{xDSL}}: {{Sidekick Compilation}} for {{SSA-Based Compilers}}},
  shorttitle = {{{xDSL}}},
  booktitle = {Proceedings of the 23rd {{ACM}}/{{IEEE International Symposium}} on {{Code Generation}} and {{Optimization}}},
  author = {Fehr, Mathieu and Weber, Michel and Ulmann, Christian and Lopoukhine, Alexandre and Lücke, Martin Paul and Degioanni, Théo and Vasiladiotis, Christos and Steuwer, Michel and Grosser, Tobias},
  date = {2025-03-01},
  series = {{{CGO}} '25},
  pages = {179--192},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3696443.3708945},
  url = {https://dl.acm.org/doi/10.1145/3696443.3708945},
  urldate = {2025-04-11},
  abstract = {Traditionally, compiler researchers either conduct experiments within an existing production compiler or develop their own prototype compiler; both options come with trade-offs.                                On one hand, prototyping in a production compiler can be cumbersome, as they are often optimized for program compilation speed at the expense of software simplicity and development speed.                                On the other hand, the transition from a prototype compiler to production requires significant engineering work.                                To bridge this gap, we introduce the concept of sidekick compiler frameworks, an approach that uses multiple frameworks that interoperate with each other by leveraging textual interchange formats and declarative descriptions of abstractions.                                Each such compiler framework is specialized for specific use cases, such as performance or prototyping.                                Abstractions are by design shared across frameworks, simplifying the transition from prototyping to production.                                We demonstrate this idea with xDSL, a sidekick for MLIR focused on prototyping and teaching.                                xDSL interoperates with MLIR through a shared textual IR and the exchange of IRs through an IR Definition Language.                                The benefits of sidekick compiler frameworks are evaluated by showing on three use cases how xDSL impacts their development: teaching, DSL compilation, and rewrite system prototyping.                                We also investigate the trade-offs that xDSL offers, and demonstrate how we simplify the transition between frameworks using the IRDL dialect.                                With sidekick compilation, we envision a future in which engineers minimize the cost of development by choosing a framework built for their immediate needs, and later transitioning to production with minimal overhead.},
  isbn = {979-8-4007-1275-3},
  file = {/Users/edjg/Zotero/storage/7YEB29W8/Fehr et al. - 2025 - xDSL Sidekick Compilation for SSA-Based Compilers.pdf}
}

@inproceedings{fuchsAcceleratorWallLimits2019,
  title = {The {{Accelerator Wall}}: {{Limits}} of {{Chip Specialization}}},
  shorttitle = {The {{Accelerator Wall}}},
  booktitle = {2019 {{IEEE International Symposium}} on {{High Performance Computer Architecture}} ({{HPCA}})},
  author = {Fuchs, Adi and Wentzlaff, David},
  date = {2019-02},
  pages = {1--14},
  issn = {2378-203X},
  doi = {10.1109/HPCA.2019.00023},
  url = {https://ieeexplore.ieee.org/document/8675237},
  urldate = {2024-10-14},
  abstract = {Specializing chips using hardware accelerators has become the prime means to alleviate the gap between the growing computational demands and the stagnating transistor budgets caused by the slowdown of CMOS scaling. Much of the benefits of chip specialization stems from optimizing a computational problem within a given chip's transistor budget. Unfortunately, the stagnation of the number of transistors available on a chip will limit the accelerator design optimization space, leading to diminishing specialization returns, ultimately hitting an accelerator wall. In this work, we tackle the question of what are the limits of future accelerators and chip specialization? We do this by characterizing how current accelerators depend on CMOS scaling, based on a physical modeling tool that we constructed using datasheets of thousands of chips. We identify key concepts used in chip specialization, and explore case studies to understand how specialization has progressed over time in different applications and chip platforms (e.g., GPUs, FPGAs, ASICs)1. Utilizing these insights, we build a model which projects forward to see what future gains can and cannot be enabled from chip specialization. A quantitative analysis of specialization returns and technological boundaries is critical to help researchers understand the limits of accelerators and develop methods to surmount them.},
  eventtitle = {2019 {{IEEE International Symposium}} on {{High Performance Computer Architecture}} ({{HPCA}})},
  keywords = {Accelerator Wall,CMOS Scaling,Computer architecture,Field programmable gate arrays,Mathematical model,Measurement,Moore's Law,Semiconductor device modeling,Throughput,Transistors},
  file = {/Users/edjg/Zotero/storage/QW8SWZBJ/Fuchs and Wentzlaff - 2019 - The Accelerator Wall Limits of Chip Specialization.pdf;/Users/edjg/Zotero/storage/BGKNDB7P/8675237.html}
}

@software{gaoVizTracer2025,
  title = {{{VizTracer}}},
  author = {Gao, Tian},
  date = {2025-04-28T14:34:17Z},
  origdate = {2020-08-05T00:29:56Z},
  url = {https://github.com/gaogaotiantian/viztracer},
  urldate = {2025-04-28},
  abstract = {A debugging and profiling tool that can trace and visualize python code execution}
}

@article{goldthwaite2006technical,
  title = {Technical Report on {{C}}++ Performance},
  author = {Goldthwaite, Lois},
  date = {2006},
  journaltitle = {ISO/IEC PDTR},
  volume = {18015},
  file = {/Users/edjg/Zotero/storage/ASSTU7N8/Goldthwaite - 2006 - Technical report on C++ performance.pdf}
}

@software{guidovanrossumPythonCpython2025,
  title = {Python/Cpython},
  author = {{Guido van Rossum}},
  date = {2025-04-28T14:44:57Z},
  origdate = {2017-02-10T19:23:51Z},
  url = {https://github.com/python/cpython},
  urldate = {2025-04-28},
  abstract = {The Python programming language},
  organization = {Python}
}

@incollection{harris2021understanding,
  title = {Understanding Computation Time: A Critical Discussion of Time as a Computational Performance Metric},
  booktitle = {Time in Variance},
  author = {Harris-Birtill, David and Harris-Birtill, Rose},
  date = {2021},
  pages = {220--248},
  publisher = {Brill},
  file = {/Users/edjg/Zotero/storage/S7HA4J9C/Harris-Birtill and Harris-Birtill - 2021 - Understanding computation time a critical discussion of time as a computational performance metric.pdf}
}

@book{hennessyComputerArchitectureQuantitative2012,
  title = {Computer {{Architecture}}: {{A Quantitative Approach}}},
  shorttitle = {Computer {{Architecture}}},
  author = {Hennessy, John L. and Patterson, David A.},
  date = {2012},
  publisher = {Elsevier},
  abstract = {Computer Architecture: A Quantitative Approach, Fifth Edition, explores the ways that software and technology in the cloud are accessed by digital media, such as cell phones, computers, tablets, and other mobile devices. The book, which became a part of Intel's 2012 recommended reading list for developers, covers the revolution of mobile computing. It also highlights the two most important factors in architecture today: parallelism and memory hierarchy. This fully updated edition is comprised of six chapters that follow a consistent framework: explanation of the ideas in each chapter; a crosscutting issues section, which presents how the concepts covered in one chapter connect with those given in other chapters; a putting it all together section that links these concepts by discussing how they are applied in real machine; and detailed examples of misunderstandings and architectural traps commonly encountered by developers and architects. Formulas for energy, static and dynamic power, integrated circuit costs, reliability, and availability are included. The book also covers virtual machines, SRAM and DRAM technologies, and new material on Flash memory. Other topics include the exploitation of instruction-level parallelism in high-performance processors, superscalar execution, dynamic scheduling and multithreading, vector architectures, multicore processors, and warehouse-scale computers (WSCs). There are updated case studies and completely new exercises. Additional reference appendices are available online. This book will be a valuable reference for computer architects, programmers, application developers, compiler and system software developers, computer system designers and application developers.   Part of Intel's 2012 Recommended Reading List for Developers Updated to cover the mobile computing revolution Emphasizes the two most important topics in architecture today: memory hierarchy and parallelism in all its forms. Develops common themes throughout each chapter: power, performance, cost, dependability, protection, programming models, and emerging trends ("What's Next") Includes three review appendices in the printed text. Additional reference appendices are available online. Includes updated Case Studies and completely new exercises.},
  isbn = {978-0-12-383872-8},
  langid = {english},
  pagetotal = {858},
  keywords = {Computers / Computer Architecture},
  file = {/Users/edjg/Zotero/storage/4TJ2CFD6/Hennessy and Patterson - 2012 - Computer Architecture A Quantitative Approach.pdf}
}

@inproceedings{holzleOptimizingDynamicallydispatchedCalls1994,
  title = {Optimizing Dynamically-Dispatched Calls with Run-Time Type Feedback},
  booktitle = {Proceedings of the {{ACM SIGPLAN}} 1994 Conference on {{Programming}} Language Design and Implementation},
  author = {Hölzle, Urs and Ungar, David},
  date = {1994-06-01},
  series = {{{PLDI}} '94},
  pages = {326--336},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/178243.178478},
  url = {https://dl.acm.org/doi/10.1145/178243.178478},
  urldate = {2025-05-12},
  isbn = {978-0-89791-662-2},
  file = {/Users/edjg/Zotero/storage/4AMQL6SQ/Hölzle and Ungar - 1994 - Optimizing dynamically-dispatched calls with run-time type feedback.pdf}
}

@incollection{Hunt2023,
  title = {Monkey Patching},
  booktitle = {A Beginners Guide to Python 3 Programming},
  author = {Hunt, John},
  date = {2023},
  pages = {487--490},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-031-35122-8_43},
  url = {https://doi.org/10.1007/978-3-031-35122-8_43},
  abstract = {Monkey Patching is a term you might well come across when looking into Python further or when searching the web for Python related concepts. It relates to the ability in Python to extend the functionality associated with a class/type at runtime.},
  isbn = {978-3-031-35122-8}
}

@standard{internationalorganizationforstandardizationISOIEC148821998,
  title = {{{ISO}}/{{IEC}} 14882:1998 {{Programming}} Languages — {{C}}++},
  shorttitle = {{{ISO}} / {{IEC}} 14882 International Standard - First Edition 1998-09-01},
  author = {{International Organization for Standardization}},
  date = {1998},
  url = {https://www.iso.org/standard/25845.html},
  urldate = {2025-06-04}
}

@online{iwonakotlarskaOptimisingCompilerPerformance2024,
  title = {Optimising {{Compiler Performance}}: {{A Case For Devirtualisation}}},
  shorttitle = {Optimising {{Compiler Performance}}},
  author = {{Iwona Kotlarska}},
  date = {2024-05-21T09:32:00+00:00},
  url = {https://www.hudsonrivertrading.com/hrtbeat/optimising-compiler-performance-a-case-for-devirtualisation/},
  urldate = {2025-06-10},
  abstract = {In the realm of high frequency trading, speed is critical. Programmers working on production systems at firms such as HRT must write code that is highly performant without compromising correctness. To achieve that, we should be aware of how compilers work, the ways they can optimise our code, and potential limitations. Let’s dive a bit deeper into one type of optimisation that compilers perform - devirtualisation.},
  langid = {american},
  organization = {Hudson River Trading},
  file = {/Users/edjg/Zotero/storage/W93MSM2J/optimising-compiler-performance-a-case-for-devirtualisation.html}
}

@online{joshhabermanTailCallingInterpreter2025,
  title = {A {{Tail Calling Interpreter For Python}} ({{And Other Updates}})},
  author = {{Josh Haberman}},
  date = {2025-10-02},
  url = {https://blog.reverberate.org/2025/02/10/tail-call-updates.html},
  urldate = {2025-05-14},
  file = {/Users/edjg/Zotero/storage/LGPDYQWY/tail-call-updates.html}
}

@online{kempenItsNotEasy2025,
  title = {It's {{Not Easy Being Green}}: {{On}} the {{Energy Efficiency}} of {{Programming Languages}}},
  shorttitle = {It's {{Not Easy Being Green}}},
  author = {family=Kempen, given=Nicolas, prefix=van, useprefix=false and Kwon, Hyuk-Je and Nguyen, Dung Tuan and Berger, Emery D.},
  date = {2025-03-28},
  eprint = {2410.05460},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2410.05460},
  url = {http://arxiv.org/abs/2410.05460},
  urldate = {2025-05-11},
  abstract = {Does the choice of programming language affect energy consumption? Previous highly visible studies have established associations between certain programming languages and energy consumption. A causal misinterpretation of this work has led academics and industry leaders to use or support certain languages based on their claimed impact on energy consumption. This paper tackles this causal question directly. It first corrects and improves the measurement methodology used by prior work. It then develops a detailed causal model capturing the complex relationship between programming language choice and energy consumption. This model identifies and incorporates several critical but previously overlooked factors that affect energy usage. These factors, such as distinguishing programming languages from their implementations, the impact of the application implementations themselves, the number of active cores, and memory activity, can significantly skew energy consumption measurements if not accounted for. We show -- via empirical experiments, improved methodology, and careful examination of anomalies -- that when these factors are controlled for, notable discrepancies in prior work vanish. Our analysis suggests that the choice of programming language implementation has no significant impact on energy consumption beyond execution time.},
  pubstate = {prepublished},
  keywords = {Computer Science - Performance,Computer Science - Programming Languages},
  file = {/Users/edjg/Zotero/storage/C65BSPZP/Kempen et al. - 2025 - It's Not Easy Being Green On the Energy Efficiency of Programming Languages.pdf;/Users/edjg/Zotero/storage/WLEKD4IA/2410.html}
}

@incollection{knuthEarlyDevelopmentProgramming1980,
  title = {The {{Early Development}} of {{Programming Languages}}*†},
  booktitle = {A {{History}} of {{Computing}} in the {{Twentieth Century}}},
  author = {Knuth, DONALD E. and Pardo, LUIS TRABB},
  editor = {Metropolis, N. and Howlett, J. and Rota, GIAN-CARLO},
  date = {1980-01-01},
  pages = {197--273},
  publisher = {Academic Press},
  location = {San Diego},
  doi = {10.1016/B978-0-12-491650-0.50019-8},
  url = {https://www.sciencedirect.com/science/article/pii/B9780124916500500198},
  urldate = {2025-06-07},
  abstract = {This paper surveys the evolution of “high-lever” programming languages during the first decade of computer programming activity. We discuss the contributions of Zuse in 1945 (the “Plankalkül”), Goldstine and von Neumann in 1946 (“Flow Diagrams”), Curry in 1948 (“Composition”), Mauchly et al. in 1949 (“Short Code”), Burks in 1950 (“Intermediate PL”), Rutishauser in 1951 (“Klammerausdrücke”), Böhm in 1951 (“Formules”), Glennie in 1952 (“AUTOCODE”), Hopper et al. in 1953 (“A-2”), Laning and Zierler in 1953 (“Algebraic Interpreter”), Backus et al. in 1954–1957 (“FORTRAN”), Brooker in 1954 (“Mark I AUTOCODE”), Kamynin and Lîubimskii in 1954 (“ΠΠ-2”), Ershov in 1955 (“ΠΠ”), Grems and Porter in 1955 (“BACAIC”), Elsworth et al. in 1955 (“Kompiler 2”), Blum in 1956 (“ADES”), Perlis et al. in 1956 (“IT”), Katz et al. in 1956–1958 (“MATH-MATIC”), Bauer and Samelson in 1956–1958 (U.S. Patent 3,047,228). The principal features of each contribution are illustrated and discussed. For purposes of comparison, a particular fixed algorithm has been encoded (as far as possible) in each of the languages. This research is based primarily on unpublished source materials, and the authors hope that they have been able to compile a fairly complete picture of the early developments in this area.},
  isbn = {978-0-12-491650-0},
  file = {/Users/edjg/Zotero/storage/6NW7CQ66/Knuth and Pardo - 1980 - The Early Development of Programming Languages†.pdf;/Users/edjg/Zotero/storage/4ZKXNJWI/B9780124916500500198.html}
}

@online{kunalbhallaUnreasonableEffectivenessSyssettrace,
  title = {The Unreasonable Effectiveness of Sys.Settrace (and Sys.Setprofile)},
  author = {{Kunal Bhalla}},
  url = {https://explog.in/notes/settrace.html},
  urldate = {2025-05-17},
  file = {/Users/edjg/Zotero/storage/YS9NUUL8/settrace.html}
}

@inproceedings{laaberEvaluationOpensourceSoftware2018,
  title = {An Evaluation of Open-Source Software Microbenchmark Suites for Continuous Performance Assessment},
  booktitle = {Proceedings of the 15th {{International Conference}} on {{Mining Software Repositories}}},
  author = {Laaber, Christoph and Leitner, Philipp},
  date = {2018-05-28},
  series = {{{MSR}} '18},
  pages = {119--130},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3196398.3196407},
  url = {https://dl.acm.org/doi/10.1145/3196398.3196407},
  urldate = {2025-04-24},
  abstract = {Continuous integration (CI) emphasizes quick feedback to developers. This is at odds with current practice of performance testing, which predominantely focuses on long-running tests against entire systems in production-like environments. Alternatively, software microbenchmarking attempts to establish a performance baseline for small code fragments in short time. This paper investigates the quality of microbenchmark suites with a focus on suitability to deliver quick performance feedback and CI integration. We study ten open-source libraries written in Java and Go with benchmark suite sizes ranging from 16 to 983 tests, and runtimes between 11 minutes and 8.75 hours. We show that our study subjects include benchmarks with result variability of 50\% or higher, indicating that not all benchmarks are useful for reliable discovery of slowdowns. We further artificially inject actual slowdowns into public API methods of the study subjects and test whether test suites are able to discover them. We introduce a performance-test quality metric called the API benchmarking score (ABS). ABS represents a benchmark suite's ability to find slowdowns among a set of defined core API methods. Resulting benchmarking scores (i.e., fraction of discovered slowdowns) vary between 10\% and 100\% for the study subjects. This paper's methodology and results can be used to (1) assess the quality of existing microbenchmark suites, (2) select a set of tests to be run as part of CI, and (3) suggest or generate benchmarks for currently untested parts of an API.},
  isbn = {978-1-4503-5716-6},
  file = {/Users/edjg/Zotero/storage/8MD74V8C/Laaber and Leitner - 2018 - An evaluation of open-source software microbenchmark suites for continuous performance assessment.pdf}
}

@inproceedings{lamNumbaLLVMbasedPython2015,
  title = {Numba: A {{LLVM-based Python JIT}} Compiler},
  shorttitle = {Numba},
  booktitle = {Proceedings of the {{Second Workshop}} on the {{LLVM Compiler Infrastructure}} in {{HPC}}},
  author = {Lam, Siu Kwan and Pitrou, Antoine and Seibert, Stanley},
  date = {2015-11-15},
  series = {{{LLVM}} '15},
  pages = {1--6},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/2833157.2833162},
  url = {https://dl.acm.org/doi/10.1145/2833157.2833162},
  urldate = {2025-05-11},
  abstract = {Dynamic, interpreted languages, like Python, are attractive for domain-experts and scientists experimenting with new ideas. However, the performance of the interpreter is often a barrier when scaling to larger data sets. This paper presents a just-in-time compiler for Python that focuses in scientific and array-oriented computing. Starting with the simple syntax of Python, Numba compiles a subset of the language into efficient machine code that is comparable in performance to a traditional compiled language. In addition, we share our experience in building a JIT compiler using LLVM[1].},
  isbn = {978-1-4503-4005-2},
  file = {/Users/edjg/Zotero/storage/YIM4DLPJ/Lam et al. - 2015 - Numba a LLVM-based Python JIT compiler.pdf}
}

@article{landinNext700Programming1966,
  title = {The next 700 Programming Languages},
  author = {Landin, P. J.},
  date = {1966-03-01},
  journaltitle = {Commun. ACM},
  volume = {9},
  number = {3},
  pages = {157--166},
  issn = {0001-0782},
  doi = {10.1145/365230.365257},
  url = {https://dl.acm.org/doi/10.1145/365230.365257},
  urldate = {2025-05-10},
  abstract = {A family of unimplemented computing languages is described that is intended to span differences of application area by a unified framework. This framework dictates the rules about the uses of user-coined names, and the conventions about characterizing functional relationships. Within this framework the design of a specific language splits into two independent parts. One is the choice of written appearances of programs (or more generally, their physical representation). The other is the choice of the abstract entities (such as numbers, character-strings, list of them, functional relations among them) that can be referred to in the language.The system is biased towards “expressions” rather than “statements.” It includes a nonprocedural (purely functional) subsystem that aims to expand the class of users' needs that can be met by a single print-instruction, without sacrificing the important properties that make conventional right-hand-side expressions easy to construct and understand.},
  file = {/Users/edjg/Zotero/storage/ZYESTFPK/Landin - 1966 - The next 700 programming languages.pdf}
}

@inproceedings{lattnerLLVMCompilationFramework2004,
  title = {{{LLVM}}: A Compilation Framework for Lifelong Program Analysis \& Transformation},
  shorttitle = {{{LLVM}}},
  booktitle = {International {{Symposium}} on {{Code Generation}} and {{Optimization}}, 2004. {{CGO}} 2004.},
  author = {Lattner, C. and Adve, V.},
  date = {2004-03},
  pages = {75--86},
  doi = {10.1109/CGO.2004.1281665},
  url = {https://ieeexplore.ieee.org/abstract/document/1281665},
  urldate = {2024-11-18},
  abstract = {We describe LLVM (low level virtual machine), a compiler framework designed to support transparent, lifelong program analysis and transformation for arbitrary programs, by providing high-level information to compiler transformations at compile-time, link-time, run-time, and in idle time between runs. LLVM defines a common, low-level code representation in static single assignment (SSA) form, with several novel features: a simple, language-independent type-system that exposes the primitives commonly used to implement high-level language features; an instruction for typed address arithmetic; and a simple mechanism that can be used to implement the exception handling features of high-level languages (and setjmp/longjmp in C) uniformly and efficiently. The LLVM compiler framework and code representation together provide a combination of key capabilities that are important for practical, lifelong analysis and transformation of programs. To our knowledge, no existing compilation approach provides all these capabilities. We describe the design of the LLVM representation and compiler framework, and evaluate the design in three ways: (a) the size and effectiveness of the representation, including the type information it provides; (b) compiler performance for several interprocedural problems; and (c) illustrative examples of the benefits LLVM provides for several challenging compiler problems.},
  eventtitle = {International {{Symposium}} on {{Code Generation}} and {{Optimization}}, 2004. {{CGO}} 2004.},
  keywords = {Algorithm design and analysis,Application software,Arithmetic,High level languages,Information analysis,Performance analysis,Program processors,Runtime,Software safety,Virtual machining},
  file = {/Users/edjg/Zotero/storage/KPM23KWZ/Lattner and Adve - 2004 - LLVM a compilation framework for lifelong program analysis & transformation.pdf;/Users/edjg/Zotero/storage/W7FDUUG6/1281665.html}
}

@software{lattnerLlvmLlvmproject2025,
  title = {Llvm/Llvm-Project},
  author = {Lattner, Chris},
  date = {2025-04-11T13:00:48Z},
  origdate = {2016-12-07T09:39:33Z},
  url = {https://github.com/llvm/llvm-project},
  urldate = {2025-04-11},
  abstract = {The LLVM Project is a collection of modular and reusable compiler and toolchain technologies.},
  organization = {LLVM}
}

@inproceedings{lattnerMLIRScalingCompiler2021a,
  title = {{{MLIR}}: {{Scaling Compiler Infrastructure}} for {{Domain Specific Computation}}},
  shorttitle = {{{MLIR}}},
  booktitle = {2021 {{IEEE}}/{{ACM International Symposium}} on {{Code Generation}} and {{Optimization}} ({{CGO}})},
  author = {Lattner, Chris and Amini, Mehdi and Bondhugula, Uday and Cohen, Albert and Davis, Andy and Pienaar, Jacques and Riddle, River and Shpeisman, Tatiana and Vasilache, Nicolas and Zinenko, Oleksandr},
  date = {2021-02},
  pages = {2--14},
  doi = {10.1109/CGO51591.2021.9370308},
  url = {https://ieeexplore.ieee.org/abstract/document/9370308},
  urldate = {2025-04-11},
  abstract = {This work presents MLIR, a novel approach to building reusable and extensible compiler infrastructure. MLIR addresses software fragmentation, compilation for heterogeneous hardware, significantly reducing the cost of building domain specific compilers, and connecting existing compilers together. MLIR facilitates the design and implementation of code generators, translators and optimizers at different levels of abstraction and across application domains, hardware targets and execution environments. The contribution of this work includes (1) discussion of MLIR as a research artifact, built for extension and evolution, while identifying the challenges and opportunities posed by this novel design, semantics, optimization specification, system, and engineering. (2) evaluation of MLIR as a generalized infrastructure that reduces the cost of building compilers-describing diverse use-cases to show research and educational opportunities for future programming languages, compilers, execution environments, and computer architecture. The paper also presents the rationale for MLIR, its original design principles, structures and semantics.},
  eventtitle = {2021 {{IEEE}}/{{ACM International Symposium}} on {{Code Generation}} and {{Optimization}} ({{CGO}})},
  keywords = {Buildings,Generators,Hardware,Optimization,Program processors,Semantics,Software},
  file = {/Users/edjg/Zotero/storage/GW75VWA5/Lattner et al. - 2021 - MLIR Scaling Compiler Infrastructure for Domain Specific Computation.pdf}
}

@online{liangUnderstandVtableAssembly,
  title = {Understand {{C}}++ Vtable from Assembly Code (Part 1)},
  author = {Liang, Guihao},
  url = {https://guihao-liang.github.io/2020/05/30/what-is-vtable-in-cpp},
  urldate = {2025-06-11},
  abstract = {A glance at vtable implementation},
  langid = {english},
  file = {/Users/edjg/Zotero/storage/T325GS7P/what-is-vtable-in-cpp.html}
}

@inproceedings{lionInvestigatingManagedLanguage2022,
  title = {Investigating {{Managed Language Runtime Performance}}: {{Why}} \{\vphantom\}{{JavaScript}}\vphantom\{\} and {{Python}} Are 8x and 29x Slower than {{C}}++, yet {{Java}} and {{Go}} Can Be {{Faster}}?},
  shorttitle = {Investigating {{Managed Language Runtime Performance}}},
  author = {Lion, David and Chiu, Adrian and Stumm, Michael and Yuan, Ding},
  date = {2022},
  pages = {835--852},
  url = {https://www.usenix.org/conference/atc22/presentation/lion},
  urldate = {2025-05-11},
  eventtitle = {2022 {{USENIX Annual Technical Conference}} ({{USENIX ATC}} 22)},
  langid = {english},
  file = {/Users/edjg/Zotero/storage/P3UA85XD/Lion et al. - 2022 - Investigating Managed Language Runtime Performance Why JavaScript and Python are 8x and 29x slowe.pdf}
}

@online{llvmprojectLLVMsAnalysisTransform,
  title = {{{LLVM}}’s {{Analysis}} and {{Transform Passes}}},
  author = {{LLVM Project}},
  url = {https://llvm.org/docs/Passes.html#memdep-memory-dependence-analysis},
  urldate = {2025-06-11},
  organization = {LLVM 21.0.0git documentation},
  file = {/Users/edjg/Zotero/storage/ULUXRJQN/Passes.html}
}

@article{luLinkTimeOptimizationDynamic,
  title = {Link-{{Time Optimization}} of {{Dynamic Casts}} in {{C}}++ {{Programs}}},
  author = {Lu, Xufan and Lopes, Nuno P},
  journaltitle = {Proc. ACM Program. Lang.},
  url = {https://pldi25.sigplan.org/details/pldi-2025-papers/92/Link-Time-Optimization-of-Dynamic-Casts-in-C-Programs},
  issue = {PLDI},
  langid = {english},
  file = {/Users/edjg/Zotero/storage/B8HUUR5Y/Lu and Lopes - Link-Time Optimization of Dynamic Casts in C++ Programs.pdf}
}

@software{michaeldroettboomAirspeedvelocityAsv2025,
  title = {Airspeed-Velocity/Asv},
  author = {{Michael Droettboom} and {Pauli Virtanen}},
  date = {2025-04-27T07:11:05Z},
  origdate = {2013-11-07T20:43:31Z},
  url = {https://github.com/airspeed-velocity/asv},
  urldate = {2025-04-28},
  abstract = {Airspeed Velocity: A simple Python benchmarking tool with web-based reporting},
  organization = {Airspeed Velocity},
  keywords = {airspeed-velocity,benchmark,python}
}

@letter{mikepallReSuggestionsImplementing2011,
  type = {E-mail},
  title = {Re: {{Suggestions}} on Implementing an Efficient Instruction Set Simulator in {{LuaJIT2}}},
  author = {{Mike Pall}},
  date = {2011-02-15},
  url = {http://lua-users.org/lists/lua-l/2011-02/msg00742.html},
  urldate = {2025-06-01},
  file = {/Users/edjg/Zotero/storage/676Q8P62/msg00742.html}
}

@inproceedings{milojkovicItsDuckTyping2017,
  title = {It's {{Duck}} ({{Typing}}) {{Season}}!},
  booktitle = {2017 {{IEEE}}/{{ACM}} 25th {{International Conference}} on {{Program Comprehension}} ({{ICPC}})},
  author = {Milojkovic, Nevena and Ghafari, Mohammad and Nierstrasz, Oscar},
  date = {2017-05},
  pages = {312--315},
  doi = {10.1109/ICPC.2017.10},
  url = {https://ieeexplore.ieee.org/abstract/document/7961528},
  urldate = {2025-06-05},
  abstract = {Duck typing provides a way to reuse code and allow a developer to write more extensible code. At the same time, it scatters the implementation of a functionality over multiple classes and causes difficulties in program comprehension. The extent to which duck typing is used in real programs is not very well understood. We report on a preliminary study of the prevalence of duck typing in more than a thousand dynamically-typed open source software systems developed in Smalltalk. Although a small portion of the call sites in these systems is duck-typed, in half of the analysed systems at least 20\% of methods are duck-typed.},
  eventtitle = {2017 {{IEEE}}/{{ACM}} 25th {{International Conference}} on {{Program Comprehension}} ({{ICPC}})},
  keywords = {Algorithm design and analysis,cross-hierarchy polymorphism,duck typing,dynamically-typed languages,Heuristic algorithms,Inference algorithms,Java,Navigation,Open source software},
  file = {/Users/edjg/Zotero/storage/2ZPHYXVA/Milojkovic et al. - 2017 - It's Duck (Typing) Season!.pdf}
}

@online{mlirteamMLIRCodeDocumentation,
  title = {{{MLIR Code Documentation}}},
  author = {{MLIR Team}},
  url = {https://mlir.llvm.org/docs/},
  urldate = {2025-04-11},
  file = {/Users/edjg/Zotero/storage/F3EKI2E6/docs.html}
}

@online{mlirteamMLIRIncludeMlir,
  title = {{{MLIR}}: Include/Mlir/{{Support}}/{{TypeID}}.h {{Source File}}},
  author = {{MLIR Team}},
  url = {https://mlir.llvm.org/doxygen/TypeID_8h_source.html},
  urldate = {2025-06-11},
  organization = {MLIR Code Documentation},
  file = {/Users/edjg/Zotero/storage/GFADXFWQ/TypeID_8h_source.html}
}

@online{mlirteamTraitsMLIR,
  title = {Traits - {{MLIR}}},
  author = {{MLIR Team}},
  url = {https://mlir.llvm.org/docs/Traits/},
  urldate = {2025-06-11},
  organization = {MLIR Code Documentation},
  file = {/Users/edjg/Zotero/storage/75TZDAVX/Traits.html}
}

@online{nedbatchelderWickedHackPython2008,
  title = {Wicked Hack: {{Python}} Bytecode Tracing},
  shorttitle = {Wicked Hack},
  author = {{Ned Batchelder}},
  date = {2008-04-11T07:25:34},
  url = {https://nedbatchelder.com/blog/200804/wicked_hack_python_bytecode_tracing.html},
  urldate = {2025-05-17},
  abstract = {Something I’ve been noodling on since PyCon is how to improve code coverage testing in Python, in particular, finding a way to measure bytecode execution instead of just line execution. After a fruitful investigation, I know a lot more about how CPython executes code, and I’ve found a way to trace each bytecode.},
  langid = {english},
  file = {/Users/edjg/Zotero/storage/X52F35FA/wicked_hack_python_bytecode_tracing.html}
}

@online{neilconwayNumbersEveryoneShould2009,
  title = {Numbers {{Everyone Should Know}}},
  author = {{Neil Conway}},
  date = {2009-10-17T22:20:20+00:00},
  url = {https://everythingisdata.wordpress.com/2009/10/17/numbers-everyone-should-know/},
  urldate = {2025-05-17},
  abstract = {When you’re designing a performance-sensitive computer system, it is important to have an intuition for the relative costs of different operations. How much does a network I/O cost, compared …},
  langid = {english},
  organization = {Everything is Data},
  file = {/Users/edjg/Zotero/storage/K55IK6MP/numbers-everyone-should-know.html}
}

@inproceedings{pecimuthDiagnosingCompilerPerformance2023,
  title = {Diagnosing {{Compiler Performance}} by {{Comparing Optimization Decisions}}},
  booktitle = {Proceedings of the 20th {{ACM SIGPLAN International Conference}} on {{Managed Programming Languages}} and {{Runtimes}}},
  author = {Pečimúth, Andrej and Leopoldseder, David and Tůma, Petr},
  date = {2023-10-19},
  series = {{{MPLR}} 2023},
  pages = {47--61},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3617651.3622994},
  url = {https://dl.acm.org/doi/10.1145/3617651.3622994},
  urldate = {2025-06-10},
  abstract = {Modern compilers apply a set of optimization passes aiming to speed up the generated code. The combined effect of individual optimizations is difficult to predict. Thus, changes to a compiler's code may hinder the performance of generated code as an unintended consequence.   Performance regressions in compiled code are often related to misapplied optimizations. The regressions are hard to investigate, considering the vast number of compilation units and applied optimizations. A compilation unit consists of a root method and inlined methods. Thus, a method may be part of several compilation units and may be optimized differently in each. Moreover, inlining decisions are not invariant across runs of the virtual machine (VM).   We propose to solve the problem of diagnosing performance regressions by capturing the compiler's optimization decisions. We do so by representing the applied optimization phases, optimization decisions, and inlining decisions in the form of trees. This paper introduces an approach utilizing tree edit distance (TED) to detect optimization differences in a semi-automated way. We present an approach to compare optimization decisions in differently inlined methods. We employ these techniques to pinpoint the causes of performance problems in various benchmarks of the Graal compiler.},
  isbn = {979-8-4007-0380-5},
  file = {/Users/edjg/Zotero/storage/MIAP4ZXT/Pečimúth et al. - 2023 - Diagnosing Compiler Performance by Comparing Optimization Decisions.pdf}
}

@report{pep659,
  type = {PEP},
  title = {Specializing {{Adaptive Interpreter}}},
  author = {{Mark Shannon}},
  date = {2021},
  number = {659},
  url = {https://peps.python.org/pep-0659/}
}

@report{pep744,
  type = {PEP},
  title = {{{JIT Compilation}}},
  author = {{Brandt Bucher} and {Savannah Ostrowski}},
  date = {2024},
  number = {744},
  url = {https://peps.python.org/pep-0744/}
}

@online{pythonsoftwarefoundation3324DataModel,
  title = {3.3.2.4. {{Data}} Model, \_\_slots\_\_},
  author = {{Python Software Foundation}},
  url = {https://docs.python.org/3/reference/datamodel.html#slots},
  urldate = {2025-06-07},
  abstract = {Objects, values and types: Objects are Python’s abstraction for data. All data in a Python program is represented by objects or by relations between objects. (In a sense, and in conformance to Von ...},
  langid = {english},
  organization = {Python documentation},
  file = {/Users/edjg/Zotero/storage/8VCEFUX6/datamodel.html}
}

@online{pythonsoftwarefoundationPythonProfilers,
  title = {The {{Python Profilers}}},
  author = {{Python Software Foundation}},
  url = {https://docs.python.org/3/library/profile.html},
  urldate = {2025-05-28},
  abstract = {Source code: Lib/profile.py and Lib/pstats.py Introduction to the profilers: cProfile and profile provide deterministic profiling of Python programs. A profile is a set of statistics that describes...},
  langid = {english},
  organization = {Python documentation},
  file = {/Users/edjg/Zotero/storage/V69P47SH/profile.html}
}

@online{pythonsoftwarefoundationTimeitMeasureExecution,
  title = {Timeit — {{Measure}} Execution Time of Small Code Snippets},
  author = {{Python Software Foundation}},
  url = {https://docs.python.org/3/library/timeit.html},
  urldate = {2025-05-28},
  abstract = {Source code: Lib/timeit.py This module provides a simple way to time small bits of Python code. It has both a Command-Line Interface as well as a callable one. It avoids a number of common traps fo...},
  langid = {english},
  organization = {Python documentation},
  file = {/Users/edjg/Zotero/storage/HDM73KJL/timeit.html}
}

@software{rickerbyPyinstrument2025,
  title = {Pyinstrument},
  author = {Rickerby, Joe},
  date = {2025-05-28T17:17:39Z},
  origdate = {2014-03-13T17:53:13Z},
  url = {https://github.com/joerick/pyinstrument},
  urldate = {2025-05-28},
  abstract = {🚴~Call stack profiler for Python. Shows you why your code is slow!},
  keywords = {async,django,performance,profile,profiler,python}
}

@software{robertkernPyutilsLine_profiler2025,
  title = {Pyutils/Line\_profiler},
  author = {{Robert Kern} and {Jon Crall}},
  date = {2025-05-28T09:11:49Z},
  origdate = {2019-12-10T22:26:33Z},
  url = {https://github.com/pyutils/line_profiler},
  urldate = {2025-05-28},
  abstract = {Line-by-line profiling for Python},
  organization = {OpenPyUtils}
}

@online{romanowskiHowNotBe,
  title = {How Not to Be Slow Using {{Python}}: {{Functions}} | Pawroman.Dev},
  shorttitle = {How Not to Be Slow Using {{Python}}},
  author = {Romanowski, Paweł},
  url = {https://pawroman.dev/how-not-to-be-slow-using-python-functions/},
  urldate = {2025-06-07},
  langid = {english},
  file = {/Users/edjg/Zotero/storage/ESWWE2N7/how-not-to-be-slow-using-python-functions.html}
}

@article{saavedraPerformanceCharacterizationOptimizing1995,
  title = {Performance Characterization of Optimizing Compilers},
  author = {Saavedra, R.H. and Smith, A.J.},
  date = {1995-07},
  journaltitle = {IEEE Transactions on Software Engineering},
  volume = {21},
  number = {7},
  pages = {615--628},
  issn = {1939-3520},
  doi = {10.1109/32.392982},
  url = {https://ieeexplore.ieee.org/document/392982/},
  urldate = {2025-04-24},
  abstract = {Optimizing compilers have become an essential component in achieving high levels of performance. Various simple and sophisticated optimizations are implemented at different stages of compilation to yield significant improvements, but little work has been done in characterizing the effectiveness of optimizers, or in understanding where most of this improvement comes from. We study the performance impact of optimization in the context of our methodology for CPU performance characterization based on the abstract machine model. The model considers all machines to be different implementations of the same high level language abstract machine; in previous research, the model has been used as a basis to analyze machine and benchmark performance. We show that our model can be extended to characterize the performance improvement provided by optimizers and to predict the run time of optimized programs, and measure the effectiveness of several compilers in implementing different optimization techniques.{$<>$}},
  keywords = {Application software,Central Processing Unit,Computer aided manufacturing,Computer science,Context modeling,High level languages,Optimizing compilers,Performance analysis,Predictive models,Time measurement},
  file = {/Users/edjg/Zotero/storage/7CTJVHTF/Saavedra and Smith - 1995 - Performance characterization of optimizing compilers.pdf}
}

@article{sabne2020xla,
  title = {{{XLA}}: {{Compiling}} Machine Learning for Peak Performance},
  author = {Sabne, Amit},
  date = {2020},
  journaltitle = {Google Research},
  url = {https://openxla.org/}
}

@thesis{saeed2008systematic,
  type = {phdthesis},
  title = {Systematic Review of Verification \& Validation in Dynamic Languages},
  author = {family=Saeed, given=FSM, given-i=FSM and Saeed, F},
  date = {2008},
  institution = {MS. Thesis, Blekinge Institute of Technology, Sweden},
  file = {/Users/edjg/Zotero/storage/AUBRPYLN/Saeed and Saeed - 2008 - Systematic review of verification & validation in dynamic languages.pdf}
}

@online{schwarzTPDEFastAdaptable2025,
  title = {{{TPDE}}: {{A Fast Adaptable Compiler Back-End Framework}}},
  shorttitle = {{{TPDE}}},
  author = {Schwarz, Tobias and Kamm, Tobias and Engelke, Alexis},
  date = {2025-05-28},
  url = {https://arxiv.org/abs/2505.22610v1},
  urldate = {2025-06-10},
  abstract = {Fast machine code generation is especially important for fast start-up just-in-time compilation, where the compilation time is part of the end-to-end latency. However, widely used compiler frameworks like LLVM do not prioritize fast compilation and require an extra IR translation step increasing latency even further; and rolling a custom code generator is a substantial engineering effort, especially when targeting multiple architectures. Therefore, in this paper, we present TPDE, a compiler back-end framework that adapts to existing code representations in SSA form. Using an IR-specific adapter providing canonical access to IR data structures and a specification of the IR semantics, the framework performs one analysis pass and then performs the compilation in just a single pass, combining instruction selection, register allocation, and instruction encoding. The generated target instructions are primarily derived code written in high-level language through LLVM's Machine IR, easing portability to different architectures while enabling optimizations during code generation. To show the generality of our framework, we build a new back-end for LLVM from scratch targeting x86-64 and AArch64. Performance results on SPECint 2017 show that we can compile LLVM-IR 8--24x faster than LLVM -O0 while being on-par in terms of run-time performance. We also demonstrate the benefits of adapting to domain-specific IRs in JIT contexts, particularly WebAssembly and database query compilation, where avoiding the extra IR translation further reduces compilation latency.},
  langid = {english},
  organization = {arXiv.org},
  file = {/Users/edjg/Zotero/storage/52UXUPYC/Schwarz et al. - 2025 - TPDE A Fast Adaptable Compiler Back-End Framework.pdf}
}

@unpublished{seansilvaHighVelocityArchitectureMLIR2025,
  title = {A {{High-Velocity Architecture}} for {{MLIR AI Compilers}}},
  author = {{Sean Silva}},
  date = {2025-03-11},
  url = {https://talks.cam.ac.uk/talk/index/228928},
  urldate = {2025-06-09},
  eventtitle = {{{CASCADE Poster Social}} (+ {{Compiler Tech Talk}})},
  venue = {William Gates Building, University of Cambridge}
}

@online{sergegueltonBuildingObfuscatedPython,
  title = {Building an Obfuscated {{Python}} Interpreter: We Need More Opcodes - {{Quarkslab}}'s Blog},
  author = {{Serge Guelton}},
  url = {https://blog.quarkslab.com/building-an-obfuscated-python-interpreter-we-need-more-opcodes.html},
  urldate = {2025-05-17},
  file = {/Users/edjg/Zotero/storage/VGXSZTRB/building-an-obfuscated-python-interpreter-we-need-more-opcodes.html}
}

@thesis{shannonConstructionHighperformanceVirtual2011,
  type = {phdthesis},
  title = {The Construction of High-Performance Virtual Machines for Dynamic Languages},
  author = {Shannon, Mark},
  date = {2011},
  institution = {University of Glasgow},
  url = {https://eleanor.lib.gla.ac.uk/record=b2890492},
  urldate = {2025-06-01},
  abstract = {Dynamic languages, such as Python and Ruby, have become more widely used over the past decade. Despite this, the standard virtual machines for these languages have disappointing performance. These virtual machines are slow, not because methods for achieving better performance are unknown, but because their implementation is hard. What makes the implementation of high-performance virtual machines difficult is not that they are large pieces of software, but that there are fundamental and complex interdependencies between their components. In order to work together correctly, the interpreter, just-in-time compiler, garbage collector and library must all conform to the same precise low-level protocols. In this dissertation I describe a method for constructing virtual machines for dynamic languages, and explain how to design a virtual machine toolkit by building it around an abstract machine. The design and implementation of such a toolkit, the Glasgow Virtual Machine Toolkit, is described. The Glasgow Virtual Machine Toolkit automatically generates a just-in-time compiler, integrates precise garbage collection into the virtual machine, and automatically manages the complex inter-dependencies between all the virtual machine components. Two different virtual machines have been constructed using the GVMT. One is a minimal implementation of Scheme; which was implemented in under three weeks to demonstrate that toolkits like the GVMT can enable the easy construction of virtual machines. The second, the HotPy VM for Python, is a high-performance virtual machine; it demonstrates that a virtual machine built with a toolkit can be fast and that the use of a toolkit does not overly constrain the high-level design. Evaluation shows that HotPy outperforms the standard Python interpreter, CPython, by a large margin, and has performance on a par with PyPy, the fastest Python VM currently available.},
  langid = {english},
  file = {/Users/edjg/Zotero/storage/AMYIA87S/Shannon - 2011 - The construction of high-performance virtual machines for dynamic languages.pdf;/Users/edjg/Zotero/storage/SJZBBNVK/2975.html}
}

@book{stallmanUsingGnuCompiler2009,
  title = {Using {{The Gnu Compiler Collection}}: {{A Gnu Manual For Gcc Version}} 4.3.3},
  shorttitle = {Using {{The Gnu Compiler Collection}}},
  author = {Stallman, Richard M. and GCC Developer Community},
  date = {2009-02},
  publisher = {CreateSpace},
  location = {Scotts Valley, CA},
  abstract = {Using the GNU COMPILER Collection. A GNU Manual for GCC Version 4.3.3. This manual documents how to use the GNU compilers, as well as their features and incompatibilities,and how to report bugs. It corresponds to the compilers (GCC) version 4.3.3.},
  isbn = {978-1-4414-1276-8}
}

@inproceedings{steeleDebunkingExpensiveProcedure1977,
  title = {Debunking the “Expensive Procedure Call” Myth or, Procedure Call Implementations Considered Harmful or, {{LAMBDA}}: {{The Ultimate GOTO}}},
  shorttitle = {Debunking the “Expensive Procedure Call” Myth or, Procedure Call Implementations Considered Harmful or, {{LAMBDA}}},
  booktitle = {Proceedings of the 1977 Annual Conference},
  author = {Steele, Guy Lewis},
  date = {1977-01-01},
  series = {{{ACM}} '77},
  pages = {153--162},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/800179.810196},
  url = {https://dl.acm.org/doi/10.1145/800179.810196},
  urldate = {2025-05-13},
  abstract = {Folklore states that GOTO statements are “cheap”, while procedure calls are “expensive”. This myth is largely a result of poorly designed language implementations. The historical growth of this myth is considered. Both theoretical ideas and an existing implementation are discussed which debunk this myth. It is shown that the unrestricted use of procedure calls permits great stylistic freedom. In particular, any flowchart can be written as a “structured” program without introducing extra variables. The difficulty with the GOTO statement and the procedure call is characterized as a conflict between abstract programming concepts and concrete language constructs.},
  isbn = {978-1-4503-3921-6},
  file = {/Users/edjg/Zotero/storage/CDD4PU2J/Steele - 1977 - Debunking the “expensive procedure call” myth or, procedure call implementations considered harmful.pdf}
}

@inproceedings{stoltzConstantPropagationFresh1994,
  title = {Constant Propagation: A Fresh, Demand-Driven Look},
  shorttitle = {Constant Propagation},
  booktitle = {Proceedings of the 1994 {{ACM}} Symposium on {{Applied}} Computing},
  author = {Stoltz, Eric and Wolfe, Michael and Gerlek, Michael P.},
  date = {1994-04-06},
  series = {{{SAC}} '94},
  pages = {400--404},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/326619.326791},
  url = {https://dl.acm.org/doi/10.1145/326619.326791},
  urldate = {2025-05-16},
  isbn = {978-0-89791-647-9},
  file = {/Users/edjg/Zotero/storage/6WAK9W8U/Stoltz et al. - 1994 - Constant propagation a fresh, demand-driven look.pdf}
}

@incollection{stroustrupHistory197919911996,
  title = {A History of {{C}}++: 1979--1991},
  shorttitle = {A History of {{C}}++},
  booktitle = {History of Programming Languages---{{II}}},
  author = {Stroustrup, Bjarne},
  date = {1996-01-01},
  pages = {699--769},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  url = {https://doi.org/10.1145/234286.1057836},
  urldate = {2025-06-04},
  abstract = {This paper outlines the history of the C++ programming language. The emphasis is on the ideas, constraints, and people that shaped the language, rather than the minutiae of language features. Key design decisions relating to language features are discussed, but the focus is one the overall design goals and practical constraints. The evolution of C++ is traced from C with Classes to the current ANSI and ISO standards work and the explosion of use, interest, commercial activity, compilers, tools, environments, and libraries.},
  isbn = {978-0-201-89502-5},
  file = {/Users/edjg/Zotero/storage/ICNTJY4M/Stroustrup - 1996 - A history of C++ 1979--1991.pdf}
}

@article{sutter2019zero,
  title = {Zero-Overhead Deterministic Exceptions: {{Throwing}} Values},
  author = {Sutter, Herb},
  date = {2019},
  journaltitle = {C++ open-std proposal P0709},
  volume = {2},
  pages = {10},
  file = {/Users/edjg/Zotero/storage/Z9FJ34TH/Sutter - 2019 - Zero-overhead deterministic exceptions Throwing values.pdf}
}

@software{thepypyteamPypyPypy2025,
  title = {Pypy/Pypy},
  author = {{The PyPy Team}},
  date = {2025-06-06T05:48:20Z},
  origdate = {2023-12-29T10:03:49Z},
  url = {https://github.com/pypy/pypy},
  urldate = {2025-06-08},
  abstract = {PyPy is a very fast and compliant implementation of the Python language.},
  organization = {PyPy}
}

@online{tomdaleAdventuresMicrobenchmarking2017,
  title = {Adventures in {{Microbenchmarking}}},
  author = {{Tom Dale}},
  date = {2017-07-15},
  url = {https://tomdale.net/2017/07/adventures-in-microbenchmarking/},
  urldate = {2025-04-24},
  organization = {tomdale.net},
  file = {/Users/edjg/Zotero/storage/LRBUXXIR/adventures-in-microbenchmarking.html}
}

@software{vaivaswathanagarajVaivaswathaPliron2025,
  title = {Vaivaswatha/Pliron},
  author = {{Vaivaswatha Nagaraj}},
  date = {2025-05-16T23:51:15Z},
  origdate = {2022-08-04T14:03:33Z},
  url = {https://github.com/vaivaswatha/pliron},
  urldate = {2025-05-17},
  abstract = {An Extensible Compiler IR Framework},
  keywords = {compilers,ir,mlir,programming-languages}
}

@online{valgrindtmdevelopersCallgrindCallgraphGenerating,
  title = {Callgrind: A Call-Graph Generating Cache and Branch Prediction Profiler},
  author = {{Valgrind™ Developers}},
  url = {https://valgrind.org/docs/manual/cl-manual.html},
  urldate = {2025-05-29},
  organization = {Valgrind},
  file = {/Users/edjg/Zotero/storage/VKF6SIAI/cl-manual.html}
}

@online{victorskvortsovPythonScenes42020,
  title = {Python behind the Scenes \#4: How {{Python}} Bytecode Is Executed},
  author = {{Victor Skvortsov}},
  date = {2020-10-30},
  url = {https://tenthousandmeters.com/blog/python-behind-the-scenes-4-how-python-bytecode-is-executed/},
  urldate = {2025-05-27},
  file = {/Users/edjg/Zotero/storage/ZN95JZGJ/python-behind-the-scenes-4-how-python-bytecode-is-executed.html}
}

@online{victorstinnerMyJourneyStable2016,
  title = {My Journey to Stable Benchmark, Part 1 (System)},
  author = {{Victor Stinner}},
  date = {2016-05-21},
  url = {https://vstinner.github.io/journey-to-stable-benchmark-system.html},
  urldate = {2025-05-14},
  file = {/Users/edjg/Zotero/storage/YMUXNYS7/journey-to-stable-benchmark-system.html}
}

@online{victorstinnerMyJourneyStable2016a,
  title = {My Journey to Stable Benchmark, Part 2 (Deadcode)},
  author = {{Victor Stinner}},
  date = {2016-05-22},
  url = {https://vstinner.github.io/journey-to-stable-benchmark-deadcode.html},
  urldate = {2025-05-14},
  file = {/Users/edjg/Zotero/storage/KLNBNB74/journey-to-stable-benchmark-deadcode.html}
}

@online{victorstinnerMyJourneyStable2016b,
  title = {My Journey to Stable Benchmark, Part 3 (Average)},
  author = {{Victor Stinner}},
  date = {2016-05-23},
  url = {https://vstinner.github.io/journey-to-stable-benchmark-average.html},
  urldate = {2025-05-14},
  file = {/Users/edjg/Zotero/storage/QLH6WL6M/journey-to-stable-benchmark-average.html}
}

@software{victorstinnerPsfPyperf2025,
  title = {Psf/Pyperf},
  author = {{Victor Stinner}},
  date = {2025-05-12T15:01:45Z},
  origdate = {2016-06-01T13:25:17Z},
  url = {https://github.com/psf/pyperf},
  urldate = {2025-05-15},
  abstract = {Toolkit to run Python benchmarks},
  organization = {Python Software Foundation},
  keywords = {benchmarking,python}
}

@thesis{wangEvaluatingSynchronizationOverhead2025,
  type = {Master of Science (MSc) in Information Technology},
  title = {Evaluating {{Synchronization Overhead}} for {{Emerging Pointer Chasing Workloads}}},
  author = {Wang, Daniel},
  date = {2025},
  institution = {Uppsala Universitet},
  location = {Uppsala, Sweden},
  url = {https://urn.kb.se/resolve?urn=urn:nbn:se:uu:diva-550341},
  urldate = {2025-06-10},
  abstract = {DiVA portal is a finding tool for research publications and student theses written at the following 50 universities and research institutions.},
  langid = {english},
  file = {/Users/edjg/Zotero/storage/TVA723TY/Wang - 2025 - Evaluating Synchronization Overhead for Emerging Pointer Chasing Workloads.pdf}
}

@online{whatsNewPython311,
  title = {What’s {{New In Python}} 3.11},
  author = {{Pablo Galindo Salgado}},
  url = {https://docs.python.org/3/whatsnew/3.11.html},
  urldate = {2025-05-10},
  abstract = {Editor, Pablo Galindo Salgado. This article explains the new features in Python 3.11, compared to 3.10. Python 3.11 was released on October 24, 2022.},
  langid = {english},
  organization = {Python documentation},
  file = {/Users/edjg/Zotero/storage/MCFX7GTA/3.11.html}
}

@online{whatsNewPython312,
  title = {What’s {{New In Python}} 3.12},
  author = {{Adam Turner}},
  url = {https://docs.python.org/3/whatsnew/3.12.html},
  urldate = {2025-05-10},
  abstract = {Editor, Adam Turner,. This article explains the new features in Python 3.12, compared to 3.11. Python 3.12 was released on October 2, 2023. For full details, see the changelog. Summary – Release hi...},
  langid = {english},
  organization = {Python documentation},
  file = {/Users/edjg/Zotero/storage/CC9F2RGA/3.12.html}
}

@online{whatsNewPython313,
  title = {What’s {{New In Python}} 3.13},
  author = {{Adam Turner} and {Thomas Wouters}},
  url = {https://docs.python.org/3/whatsnew/3.13.html},
  urldate = {2025-05-10},
  abstract = {Editors, Adam Turner and Thomas Wouters. This article explains the new features in Python 3.13, compared to 3.12. Python 3.13 was released on October 7, 2024.},
  langid = {english},
  organization = {Python documentation},
  file = {/Users/edjg/Zotero/storage/A2824J8Z/3.13.html}
}

@inproceedings{williamsDynamicInterpretationDynamic2010,
  title = {Dynamic Interpretation for Dynamic Scripting Languages},
  booktitle = {Proceedings of the 8th Annual {{IEEE}}/{{ACM}} International Symposium on {{Code}} Generation and Optimization},
  author = {Williams, Kevin and McCandless, Jason and Gregg, David},
  date = {2010-04-24},
  series = {{{CGO}} '10},
  pages = {278--287},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/1772954.1772993},
  url = {https://dl.acm.org/doi/10.1145/1772954.1772993},
  urldate = {2025-05-10},
  abstract = {Dynamic scripting languages offer programmers increased flexibility by allowing properties of programs to be defined at run-time. Typically, program execution begins with an interpreter where type checks are implemented using conditional statements. Recent JIT compilers have begun removing run-time checks by specializing native code to program properties discovered at JIT time.This paper presents a novel intermediate representation for scripting languages that explicitly encodes types of variables. The dynamic representation is a flow graph, where each node is a specialized virtual instruction and each edge directs program flow based on control and type changes in the program. The interpreter thus performs specialized execution of whole programs. We present techniques for the efficient interpretation of our representation showing speed-ups of greater than 2x over static interpretation, with an average speed-up of approximately 1.3x.},
  isbn = {978-1-60558-635-9},
  file = {/Users/edjg/Zotero/storage/FW38FJTP/Williams et al. - 2010 - Dynamic interpretation for dynamic scripting languages.pdf}
}

@article{williamsRooflineInsightfulVisual2009a,
  title = {Roofline: An Insightful Visual Performance Model for Multicore Architectures},
  shorttitle = {Roofline},
  author = {Williams, Samuel and Waterman, Andrew and Patterson, David},
  date = {2009-04-01},
  journaltitle = {Commun. ACM},
  volume = {52},
  number = {4},
  pages = {65--76},
  issn = {0001-0782},
  doi = {10.1145/1498765.1498785},
  url = {https://dl.acm.org/doi/10.1145/1498765.1498785},
  urldate = {2025-06-11},
  abstract = {The Roofline model offers insight on how to improve the performance of software and hardware.},
  file = {/Users/edjg/Zotero/storage/WYAG7UTZ/Williams et al. - 2009 - Roofline an insightful visual performance model for multicore architectures.pdf}
}

@article{wilsonSUIFInfrastructureResearch1994,
  title = {{{SUIF}}: An Infrastructure for Research on Parallelizing and Optimizing Compilers},
  shorttitle = {{{SUIF}}},
  author = {Wilson, Robert P. and French, Robert S. and Wilson, Christopher S. and Amarasinghe, Saman P. and Anderson, Jennifer M. and Tjiang, Steve W. K. and Liao, Shih-Wei and Tseng, Chau-Wen and Hall, Mary W. and Lam, Monica S. and Hennessy, John L.},
  date = {1994-12-01},
  journaltitle = {SIGPLAN Not.},
  volume = {29},
  number = {12},
  pages = {31--37},
  issn = {0362-1340},
  doi = {10.1145/193209.193217},
  url = {https://dl.acm.org/doi/10.1145/193209.193217},
  urldate = {2025-06-09},
  abstract = {Compiler infrastructures that support experimental research are crucial to the advancement of high-performance computing. New compiler technology must be implemented and evaluated in the context of a complete compiler, but developing such an infrastructure requires a huge investment in time and resources. We have spent a number of years building the SUIF compiler into a powerful, flexible system, and we would now like to share the results of our efforts.SUIF consists of a small, clearly documented kernel and a toolkit of compiler passes built on top of the kernel. The kernel defines the intermediate representation, provides functions to access and manipulate the intermediate representation, and structures the interface between compiler passes. The toolkit currently includes C and Fortran front ends, a loop-level parallelism and locality optimizer, an optimizing MIPS back end, a set of compiler development tools, and support for instructional use.Although we do not expect SUIF to be suitable for everyone, we think it may be useful for many other researchers. We thus invite you to use SUIF and welcome your contributions to this infrastructure. Directions for obtaining the SUIF software are included at the end of this paper.},
  file = {/Users/edjg/Zotero/storage/PKU76JD2/Wilson et al. - 1994 - SUIF an infrastructure for research on parallelizing and optimizing compilers.pdf}
}

@online{xuBuildingBaselineJIT2023a,
  title = {Building a Baseline {{JIT}} for {{Lua}} Automatically},
  author = {Xu, Haoran},
  date = {2023-05-12T00:00:00},
  url = {https://sillycross.github.io/2023/05/12/2023-05-12/index.html},
  urldate = {2025-05-14},
  abstract = {This is the Part 2 of a series. Feel free to read the prequel for more context: Building the fastest Lua interpreter automatically  Building a good VM for a dynamic language takes a ton of engineerin},
  file = {/Users/edjg/Zotero/storage/SUVYS5UP/2023-05-12.html}
}

@online{xuBuildingFastestLua2022a,
  title = {Building the Fastest {{Lua}} Interpreter.. Automatically!},
  author = {Xu, Haoran},
  date = {2022-11-22T00:00:00},
  url = {https://sillycross.github.io/2022/11/22/2022-11-22/index.html},
  urldate = {2025-05-14},
  abstract = {This is Part 1 of a series of posts. Part 2 is available here: Building a baseline JIT for Lua automatically  It is well-known that writing a good VM for a dynamic language is never an easy job. High},
  file = {/Users/edjg/Zotero/storage/L5FXCLMQ/2022-11-22.html}
}

@article{xuCopyandpatchCompilationFast2021a,
  title = {Copy-and-Patch Compilation: A Fast Compilation Algorithm for High-Level Languages and Bytecode},
  shorttitle = {Copy-and-Patch Compilation},
  author = {Xu, Haoran and Kjolstad, Fredrik},
  date = {2021-10-15},
  journaltitle = {Artifact for Paper "Copy-and-Patch Compilation: A fast compilation algorithm for high-level languages and bytecode"},
  shortjournal = {Proc. ACM Program. Lang.},
  volume = {5},
  pages = {136:1--136:30},
  doi = {10.1145/3485513},
  url = {https://dl.acm.org/doi/10.1145/3485513},
  urldate = {2025-06-07},
  abstract = {Fast compilation is important when compilation occurs at runtime, such as query compilers in modern database systems and WebAssembly virtual machines in modern browsers. We present copy-and-patch, an extremely fast compilation technique that also produces good quality code. It is capable of lowering both high-level languages and low-level bytecode programs to binary code, by stitching together code from a large library of binary implementation variants. We call these binary implementations stencils because they have holes where missing values must be inserted during code generation. We show how to construct a stencil library and describe the copy-and-patch algorithm that generates optimized binary code.  We demonstrate two use cases of copy-and-patch: a compiler for a high-level C-like language intended for metaprogramming and a compiler for WebAssembly. Our high-level language compiler has negligible compilation cost: it produces code from an AST in less time than it takes to construct the AST. We have implemented an SQL database query compiler on top of this metaprogramming system and show that on TPC-H database benchmarks, copy-and-patch generates code two orders of magnitude faster than LLVM -O0 and three orders of magnitude faster than higher optimization levels. The generated code runs an order of magnitude faster than interpretation and 14\% faster than LLVM -O0. Our WebAssembly compiler generates code 4.9X-6.5X faster than Liftoff, the WebAssembly baseline compiler in Google Chrome. The generated code also outperforms Liftoff's by 39\%-63\% on the Coremark and PolyBenchC WebAssembly benchmarks.},
  issue = {OOPSLA},
  file = {/Users/edjg/Zotero/storage/54SQ2BK8/Xu and Kjolstad - 2021 - Copy-and-patch compilation a fast compilation algorithm for high-level languages and bytecode.pdf}
}

@online{xuDeegenJITCapableVM2024,
  title = {Deegen: {{A JIT-Capable VM Generator}} for {{Dynamic Languages}}},
  shorttitle = {Deegen},
  author = {Xu, Haoran and Kjolstad, Fredrik},
  date = {2024-11-24},
  eprint = {2411.11469},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2411.11469},
  url = {http://arxiv.org/abs/2411.11469},
  urldate = {2025-06-01},
  abstract = {Building a high-performance JIT-capable VM for a dynamic language has traditionally required a tremendous amount of time, money, and expertise. We present Deegen, a meta-compiler that allows users to generate a high-performance JIT-capable VM for their own language at an engineering cost similar to writing a simple interpreter. Deegen takes in the execution semantics of the bytecodes implemented as C++ functions, and automatically generates a two-tier VM execution engine with a state-of-the-art interpreter, a state-of-the-art baseline JIT, and the tier-switching logic that connects them into a self-adaptive system. We are the first to demonstrate the automatic generation of a JIT compiler, and the automatic generation of an interpreter that outperforms the state of the art. Our performance comes from a long list of optimizations supported by Deegen, including bytecode specialization and quickening, register pinning, tag register optimization, call inline caching, generic inline caching, JIT polymorphic IC, JIT IC inline slab, type-check removal and strength reduction, type-based slow-path extraction and outlining, JIT hot-cold code splitting, and JIT OSR-entry. These optimizations are either employed automatically, or guided by the language implementer through intuitive APIs. As a result, the disassembly of the Deegen-generated interpreter, baseline JIT, and the generated JIT code rivals the assembly code hand-written by experts in state-of-the-art VMs. We implement LuaJIT Remake (LJR), a standard-compliant Lua 5.1 VM, using Deegen. Across 44 benchmarks, LJR's interpreter is on average 179\% faster than the official PUC Lua interpreter, and 31\% faster than LuaJIT's interpreter. LJR's baseline JIT has negligible startup delay, and its execution performance is on average 360\% faster than PUC Lua and only 33\% slower (but faster on 13/44 benchmarks) than LuaJIT's optimizing JIT.},
  pubstate = {prepublished},
  keywords = {Computer Science - Programming Languages},
  file = {/Users/edjg/Zotero/storage/G3HZMA4P/Xu and Kjolstad - 2024 - Deegen A JIT-Capable VM Generator for Dynamic Languages.pdf;/Users/edjg/Zotero/storage/N3EGFE7F/2411.html}
}
