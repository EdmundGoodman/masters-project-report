\chapter{Quantifying dynamism in compiler framework pattern rewriting}
\label{chap:dynamism-pattern-rewriting}

%% Introduction
% Hook
A key difference between the Python and C++ runtimes is their degree of dynamism.
% Argument
\ac{mlir}'s C++ runtime incurs overhead when dynamically dispatching functions (\autoref{fig:narrative}, \circledbase{pairedThreeLightGreen}{3}), which is worsened by prohibiting ahead-of-time performance optimisations. In contrast, almost every bytecode operation evaluated by the Python interpreter is dynamic, each incurring an overhead.
As such, we expect the difference in performance between language runtimes (\autoref{fig:narrative}, \circledbase{pairedFourDarkGreen}{4}) to be smaller for more dynamic workloads.
% Link
In this chapter, we quantify this difference by examining synthetic examples within static and dynamic language runtimes. We then apply this information to understand the difference in performance between pattern rewriting workloads using xDSL and \ac{mlir} through the lens of overhead incurred by dynamism.


\section{Cost of dynamic dispatch}
\label{sec:dynamism-pattern-rewriting-dispatch}

%% Introduce the issue, and where it is in the micro-benchmark
% Hook
In static languages such as C++, the exact address function calls can often be resolved at compile time. In contrast, dynamic languages such as Python must resolve the address of each function call at runtime, incurring an overhead.
% Also optimisation boundary and stuff
% Argument
However, the address of some function calls can only be known at runtime, for example as a result of object polymorphism. This address then must be resolved during execution by the language runtime in both static and dynamic languages. Furthermore, this information being known only at runtime presents and optimisation boundary, precluding common rewrites such as function inlining which contribute to the performance of ahead-of-time compiled languages.
Driesen and H\"olzle quantify the former and acknowledge the latter cost in their work ``The Direct Cost of Virtual Function Calls in C++'' \cite{driesenDirectCostVirtual1996}, which found that C++ programs spent a median of $5.2\%$ of their time in dispatch code. % TODO: Possibly pick a different metric from the paper
We argue further that the difference between static and dynamic languages is reduced for highly dynamic workloads with insufficient information to resolve function addresses ahead of time.
% Link
We justify this by examining the mechanisms of dynamic dispatch in Python and C++, and contrasting them through both synthetic examples and our micro-benchmark suite.

% Hook
% Argument
C++ uses a \ac{vtable} mechanism for method polymorphism, a lookup table which is accessed at runtime through pointer indirection to retrieve the address for the virtual function implementation. In contrast, Python stores methods and attributes in the \mintinline{text}{__dict__} object attribute which is searched at runtime, checking parent classes if needed. While both use indirection for dynamic dispatch, Python's approach enables more dynamic behaviour like runtime meta-programming but comes with higher performance costs compared to C++'s more efficient \ac{vtable} system.
% Link
We can quantify the performance overhead of this \ac{vtable} mechanism through a synthetic example (Listing \ref{listing:impact-dispatch}).


\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.45\textwidth}
       \centering
        \begin{minted}[fontsize=\scriptsize,escapeinside=££]{text}
class Base {
public:
    int func(int a, int b) { £\circledbase{pairedTwoDarkBlue}{\scriptsize{b}}£
        return a - b;
    }
    __attribute__((noinline))
    int uninlinedFunc(int a, int b) { £\circledbase{pairedThreeLightGreen}{\scriptsize{e}}£
        return a - b;
    }
    virtual int virtualFunc(int a, int b) { £\circledbase{pairedFourDarkGreen}{\scriptsize{a}}£
        return a - b;
    }
};

class Derived : public Base {
public:
    int virtualFunc(int a, int b) override {
        return b - a;
    }
};
        \end{minted}
        \scriptsize{\vspace{1em}}
        \captionsetup{name=Listing}
        \caption{Method definitions.}
        \label{listing:impact-dispatch-definition}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \begin{minted}[breakanywhere,fontsize=\scriptsize,escapeinside=££]{text}
#include <stdlib.h>

int main(int argc, char *argv[]) {
    // Values known only at runtime £\circledbase{pairedNegOneLightGray}{\scriptsize{c}}£
    int a = atoi(argv[1]), b = atoi(argv[2]), c = atoi(argv[3]);

    // Setup
    int result = 0;
    Base baseObj;
    Derived derivedObj;
    Base* polyObj = c > 0 ? &baseObj : &derivedObj; £\circledbase{pairedNegTwoDarkGray}{\scriptsize{d}}£

    // Function invocations
    result += baseObj.func(a, b);
    result += baseObj.uninlinedFunc(a, b);
    result += polyObj->virtualFunc(a, b);

    return result;
}
        \end{minted}
        \captionsetup{name=Listing}
        \caption{Method invocations.}
        \label{listing:impact-dispatch-invocation}
    \end{subfigure}
    \vspace{1em}
    \captionsetup{name=Listing}
    \caption{Synthetic example of direct and dynamic method dispatch in C++.}
    \label{listing:impact-dispatch}
\end{figure}

% Hook
This synthetic example exercises polymorphic methods which must be resolved dynamically using a \ac{vtable} at runtime \circledbase{pairedFourDarkGreen}{\scriptsize{a}}, along with methods which can be statically resolved ahead of time during compilation \circledbase{pairedTwoDarkBlue}{\scriptsize{b}}.
% Argument
A challenge when constructing this workload is providing data whose value is known only at runtime. We implement this by taking arguments from the command line \circledbase{pairedNegOneLightGray}{\scriptsize{c}}, as opposed to defining static variables which the compiler could reason about to inform ahead of time optimisations. This is necessary to exercise dynamic dispatch of functions, which requires a polymorphic object whose type is only known at runtime \circledbase{pairedNegTwoDarkGray}{\scriptsize{d}}. Since this simple synthetic example is amenable to compiler optimisations such as function inlining, we use variable attributes to hint to the compiler that certain methods should not be inlined \circledbase{pairedThreeLightGreen}{\scriptsize{e}}.
% Link

\begin{figure}[H]
    \centering
    \begin{tikzpicture}
        \node[anchor=south west,inner sep=0] (image) at (0,0) {\includegraphics[width=0.75\textwidth]{images/impact_dynamism/dispatch.pdf}};
        \node[circledstyle, fill=pairedFourDarkGreen] at (4,0.625) {a};
        \node[circledstyle, fill=pairedThreeLightGreen] at (6.95,0.625) {e};
        \node[circledstyle, fill=pairedTwoDarkBlue] at (9.9,0.75) {b};
    \end{tikzpicture}
    % \includegraphics[width=0.75\textwidth]{images/impact_dynamism/dispatch.pdf}
    \caption{Dynamic dispatch generated by \texttt{clang -O3} incurs a $30\%$ overhead in comparison with direct dispatch, but remains an order of magnitude more performant than CPython 3.10 method invocation.}
    \label{figure:impact-dispatch}
\end{figure}


% % Hook
Having constructed this synthetic example, we calculate the cost of each method invocation by measuring the runtime of each function and subtracting the runtime of its inlined implementation (\autoref{figure:impact-dispatch}).
% % Argument
Dynamic dispatch is $30\%$ slower than direct dispatch, as a result of the overhead constructing and dereferencing through the \ac{vtable}. Examining the disassembly (\autoref{chap:impact-disassembly}), this overhead increases the instruction count from $4$ to $14$, for a total of $10$ extra cycles on ARM \ac{risc} machines. This observation matches the work of Driesen and H\"olzle, who assert the ``direct cost'' of virtual function calls is up to $10.2$ cycles for highly dynamic workloads \cite[Figure 18.]{driesenDirectCostVirtual1996}.
In addition to this Driesen and H\"olzle acknowledge there is a further ``indirect cost'' associated with hidden optimisations, but do not characterise it.
An example of such an optimisation hidden by runtime information is the inlining of the function implementation. This code motion represents the remaining $70\%$ of the overhead of dynamic dispatch -- significantly greater than the polymorphism machinery. Furthermore, this is a lower bound of this impact, as further optimisations such as vectorisation or dead code elimination could be revealed.
% Link
Despite both these direct and indirect costs, Python function invocation remains an order of magnitude slower.

%% Why is python slower?
% Hook
% Python's poor performance comes as a result of...
% Argument
% Link

% %% Where does this occur?
% Hook
Functions which can only be dispatched at runtime are one way a workload can be dynamic.
% Argument
Having a high proportion of such functions is one way in which user-extensible compiler frameworks are highly dynamic. For example, since the Operation objects composing the \ac{ir} being processed are necessarily only known at runtime, their methods such as verification and printing must be dispatched dynamically.
In other cases, \ac{mlir} is optimised to avoid this cost. For example, the \mintinline{text}{TypeID::get<Traits>} function uses template meta-programming to monomorphise the generic function calls. However, this approach is only applicable when there is sufficient information at runtime.
% Link




\section{Run-time type information}
\label{sec:dynamism-pattern-rewriting-rtti}

%% Introduce the issue
% Hook
In a ``A history of C++: 1979--1991'', Stroustop states that the original C++ design ``deliberately didn't include [mechanisms] for run-time type identification [as] they were almost always misused.'' \cite{stroustrupHistory197919911996}.
% Argument
Support for this functionality was later added in C++98 \cite{internationalorganizationforstandardizationISOIEC148821998}, including support for \texttt{dynamic\_cast}s checked a runtime, and getting the \texttt{typeid} of a polymorphic object. However, this incurs a runtime cost \cite{goldthwaite2006technical}, and is brittle in the objects to which it can be applied. A such, LLVM reimplements a subset of this functionality, providing the \texttt{dyn\_cast} method and \texttt{TypeID} data structure, aiming to ``strike a balance between performance and the setup required to enable its use'' \cite{mlirteamMLIRCodeDocumentation}.
This is another example of dynamic behaviour, which we again argue incurs additional runtime overhead and precludes optimisations in static languages, closing the gap with dynamic ones.
% Link
As before, we justify this be examining the details of this mechanism, using our micro-benchmark suite.

%% Graph
\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\textwidth]{images/impact_dynamism/dynamic_cast.pdf}
    \caption{Both checking and casting LLVM \ac{rtti} have a similar runtime cost, constrasting Python, which is $10\times$ slower for checking and $25\times$ slower for casting.}
    \label{figure:impact-rtti}
\end{figure}

%% Experimental results
% Hook
We measure the duration of micro-benchmarks exercising xDSL and \ac{mlir}'s \ac{rtti} operations (\autoref{figure:impact-rtti}). LLVM's \ac{rtti} implementation is much more performant than Python, leveraging C++ templates to defer as much computation as possible to compile time. In addition to this, type checking and casting have approximately the same performance cost, as they leverage similar mechanisms.
% Argument
In contrast, Python's \texttt{isinstance} function is faster than \texttt{cast}, as the former it is implemented in C as a builtin function, whereas the latter is in Python in the standard library, hence relying on the dynamic dispatch machinery discussed above.
However, the implementation of the \texttt{cast} function is the identity, doing nothing. This is because Python's dynamic duck typing \cite{milojkovicItsDuckTyping2017} does not require restructuring data when casting, allowing casting operations and some type checks to be elided.
% Link



% \section{Object data access}
% \label{sec:dynamism-pattern-rewriting-access}

%% TODO: Depending on how re-worked the specialising chapter gets, I could add another section discussing using runtime invariants to make Python less dynamic, which would quantify __slots__








\section{Dynamism in pattern rewriting}
\label{chap:dynamism-pattern-rewriting-summary}


%% Introduction
% Hook (what we have done, and how this lets us do more)
Having quantified the impacts of dynamism on the performance of static languages for synthetic examples and micro-benchmarks, we can then apply this knowledge to pattern rewriting workloads.
% Argument
Through this, we empirically demonstrate their high degree of dynamism, and the impact that this has on both static and dynamic language implementations through the proxies of the \ac{mlir} and xDSL frameworks.
% Hook

%% Counting dynamism in constant folding
% Hook
As discussed above (\autoref{sec:dynamism-pattern-rewriting-dispatch}), one cause of dynamism in programs is dynamic dispatch, which we quantified as having both a direct and indirect cost for synthetic examples that could be analysed manually.
% Argument
However, pattern rewriting workloads are much larger, and as such are not feasible to manually analyse in the same way. We address this by using the information from our synthetic example, which provides a lower bound for the direct and indirect cost incurred by each of these dispatches. % TODO: justify lower bound
This lower bound of overhead per dispatch can then be multiplied by the number of dynamic dispatches to estimate the overall cost for pattern rewriting.
% In the ARM instruction set, direct and indirect calls \cite{armlimitedARMCortexRSeries}
% ``Because the branch destination is PC-relative, it can be determined exactly at an early stage of the pipeline''. This means that direct calls are more performant, and as such efficient compilers only use indirect calls where address information is not known ahead of time: dynamic control flow.
We use the DynamoRIO \cite{brueningInfrastructureAdaptiveDynamic2003} tool to instrument these workloads, using the \texttt{countcalls} sample to count the number of direct and indirect calls respectively (\autoref{tab:dynamorio-constant-folding}).
% Link

%% Table
\begin{table}[H]
  \caption{$17\%$ of calls are dynamically dispatched when constant folding integer addition over 20 operations (implementation \autoref{sec:specialising-pattern-rewriting-workload}, DynamoRIO results \autoref{chap:dynamorio-calls}).}
  \label{tab:dynamorio-constant-folding}
  \centering
  \begin{tabular}{cc}
    \toprule
    \textbf{Direct calls} & \textbf{Indirect calls}\\
    \midrule
    75140 & 4320 \\
    % Direct method dispatch & & \\
    % Dynamic method dispatch & & \\
    % \ac{mlir} constant folding & 75140 & 4320 \\ % 182378 - 107238
    % xDSL specialised constant folding & 0 & \\
    \bottomrule
  \end{tabular}
\end{table}

%% Estimating overhead in static languages
% Hook
We can then combine this information with our lower bound for the performance overhead of dynamic dispatch from synthetic examples to estimate the overhead due to dynamism in pattern rewriting workloads (\autoref{figure:impact-rtti}).
% Argument
% Link

%% Performance graph
\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\textwidth]{images/impact_dynamism/pattern.pdf}
    \caption{.}
    \label{figure:impact-rtti}
\end{figure}

%% Contrasting with Python
% Hook
% Argument
% Link

\section{Motivating dynamic languages for user-extensible compiler infrastructures}
\label{chap:dynamism-pattern-rewriting-motivating}

%% Summary
% Hook
% Argument
% Link
