\chapter{Introduction}
\label{chap:introduction}
% This is the introduction where you should introduce your work. In general the thing to aim for here is to describe a little bit of the context for your work -- why did you do it (motivation), what was the hoped-for outcome (aims) -- as well as trying to give a brief overview of what you actually did.
% It's often useful to bring forward some ``highlights'' into this chapter (e.g.\ some particularly compelling results, or a particularly
% interesting finding).
% It's also traditional to give an outline of the rest of the document, although without care this can appear formulaic and tedious. Your call.




%% Context (~abstract sentence one: topic of compilers/MLIR)
Compilers are a critical component of computing systems, providing an abstraction from high-level programming languages to the underlying machine ISA.
Released in 1987, \texttt{gcc} was a popular open-source compiler \cite{stallmanUsingGnuCompiler2009}, but its monolithic and tightly-coupled design impacted its re-usability.
% In the 20\textsuperscript{th} century, compilers were typically monolithic and specific to individual languages, resulting in poor re-usability.
The LLVM compiler framework \cite{lattnerLLVMCompilationFramework2004} addressed these problems with a human-readable and language-independent textual \ac{ir} in \ac{ssa} form \cite{cytronEfficientlyComputingStatic1991}, which could be analysed and transformed by a sequence of passes, made available as a re-usable C++ library.
Recently, \ac{mlir} \cite{lattnerMLIRScalingCompiler2021a}, has furthered these goals by enabling users to cheaply extend compilers with their own abstractions.




%%% "why did you do it (motivation)"

%% Context/Motivation (~abstract sentence one/two/three: extensible compiler frameworks, how this impacts performance, and that MLIR accept it)
Compiler extensibility is critical for handling the heterogeneous hardware and exotic optimisations of modern workloads.
To implement this, \ac{mlir} uses dynamic, pointer-chasing data structures and algorithms to represent its \ac{ir}. For example, pattern rewriting in \ac{mlir} traverses and pattern matches on a linked list representation of \ac{ssa} values.
This further inhibits optimisations, both as a result of dynamism and not being amenable to other transformations such as vectorisation.
These factors motivate challenging the status quo of LLVM and MLIR implementing user-extensible compiler frameworks in static, ahead-of-time compiled languages.




%%% "what was the hoped-for outcome (aims)"

%% Motivation/aim (~abstract sentence four: why not use dynamic languages/xDSL?)
% This challenge takes the form of xDSL
xDSL \cite{fehrXDSLSidekickCompilation2025} is a reimplementation of \ac{mlir}'s core data structures and \ac{ir} definitions in Python, a dynamically typed, interpreted language.
Using Python allows xDSL to take \ac{mlir}'s goal of user extensibility to even further extremes by leveraging its dynamic features such as runtime meta-programming.
In addition to this, xDSL's interpreted nature avoids \ac{mlir}'s long build times, and its dynamic typing matching the dynamic nature of the user-extensible compiler framework workload.
% xDSL's implementation in Python avoids the long build times of \ac{mlir} as a result of being interpreted. %, and its expressive syntax and minimal boilerplate allows compiler designers to focus on their task as opposed to the underlying language and framework.
% In addition to this, Python's dynamic typing matches the dynamic nature of the user-extensible compiler framework workload.
However, using Python also has drawbacks, most notably in relation to runtime performance.
This work examines the performance of the pattern rewriting component of the xDSL compiler framework, focussing on the impact of dynamism and contrasting against the current state-of-the-art, \ac{mlir}.



%%% "give a brief overview of what you actually did"

%% Overview (~abstract sentence five, which needs re-writing: what we did part one -- specialisation and CPython stuff)
The performance of a program is constrained both by the details of its implementation and the runtime of its language.
These two properties are deeply interlinked, making them difficult to measure independently.
To disentangle them, we manually optimise and specialise xDSL's implementation of pattern rewriting (\autoref{fig:narrative}, \circledbase{pairedOneLightBlue}{1}), resulting in an $7\times$ performance uplift.
We then confirm that the performance of the specialisation is constrained only by the language runtime by examination of the dispatched bytecode of micro-benchmarks.
This bytecode examination process revealed a gap in the provision of fine grained performance profilers for Python. To address this gap, we developed ByteSight, native tracing performance profiler for Python bytecode.
We then use this tool to quantify the impact of recent performance enhancements made to CPython for this specialised implementation (\autoref{fig:narrative}, \circledbase{pairedTwoDarkBlue}{2}).
This describes the best-case for the performance of pattern rewriting in xDSL, which can then be compared against \ac{mlir}.

\begin{figure}[H]
    \centering
    \begin{tikzpicture}
        % \node[anchor=south west,inner sep=0] (image) at (0,0) {\includegraphics[width=0.6\textwidth]{images/introduction/narrative.drawio.pdf}};
        \node[anchor=south west,inner sep=0] (image) at (0,0) {\includegraphics[width=0.75\textwidth]{images/introduction/narrative.drawio.pdf}};
        % \node[circledstyle, fill=pairedOneLightBlue] at (4.35,5.05) {1};
        \node[circledstyle, fill=pairedOneLightBlue] at (5.45,6.325) {1};
        % \node[circledstyle, fill=pairedTwoDarkBlue] at (5.55,4.15) {2};
        \node[circledstyle, fill=pairedTwoDarkBlue] at (6.95,5.2) {2};
        % \node[circledstyle, fill=pairedThreeLightGreen] at (6.95,2.7) {3};
        \node[circledstyle, fill=pairedThreeLightGreen] at (8.7,3.35) {3};
        % \node[circledstyle, fill=pairedFourDarkGreen] at (8.75,1.95) {4};
        \node[circledstyle, fill=pairedFourDarkGreen] at (10.8,2.4) {4};
    \end{tikzpicture}
    % \includegraphics[width=0.6\textwidth]{images/introduction/narrative.drawio.pdf}
    \caption{Closing the gap between xDSL and \ac{mlir} pattern rewriting performance. xDSL's performance can be improved by changes to both its implementation and language runtime. C++ has less of a performance advantage for \ac{mlir} than other workloads due to the costs associated with dynamism.}
    \label{fig:narrative}
\end{figure}


%% Overview (~abstract sentence five, which needs re-writing: what we did part two -- custom CPython optimisations)
% Hook
% Argument
% Link


%% Overview (~abstract sentence five, which needs re-writing: what we did part three -- cost of dynamism)
A key difference between the Python and C++ runtimes is their degree of language dynamism.
\ac{mlir}'s C++ runtime incurs overhead when dynamically dispatching functions (\autoref{fig:narrative}, \circledbase{pairedThreeLightGreen}{3}), which is worsened by prohibiting ahead-of-time performance optimisations. In contrast, almost every bytecode operation evaluated by the Python interpreter is dynamic, each incurring an overhead checking runtime information.
As such, we expect the difference in performance between language runtimes (\autoref{fig:narrative}, \circledbase{pairedFourDarkGreen}{4}) to be smaller for more dynamic workloads.
To corroborate this, we measure the difference in performance between pattern rewriting workloads using xDSL and \ac{mlir}, and assess the contribution of overheads incurred by dynamism.
This measurement procedure uniquely leverages xDSL's sidekick compilation functionality to ensure the comparability of performance measurements by driving them with the same textual \ac{ir}, even for implementation details internal to each framework.
Finally, we critically evaluate the degree to which this motivates the use of Python for implementing user-extensible compiler frameworks.



%% Contributions (~abstract sentence six: key impact of research)
The contributions of our work are as follows:

\begin{itemize}
    \item An examination of the current %and best-case
    performance of pattern rewriting workloads in the CPython language runtime (\autoref{chap:measuring-compiler-performance}).%(\autoref{chap:measuring-compiler-performance} and \autoref{chap:specialising-optimising-pattern-rewriting} respectively). %, including trade-offs in expressivity and the impact of performance optimisations made to the language runtime.
    \item A tool to examine CPython bytecode dispatch in program runs, facilitating the analysis of costs incurred by dynamism (\autoref{chap:profiling-bytecode}).
    \item A specialisation of the current xDSL implementation for pattern rewriting workloads, demonstrating the best-case performance of CPython for such applications (\autoref{chap:specialising-optimising-pattern-rewriting}).
    \item An exploration of optimisation techniques to shrink the performance gap between dynamic and static languages for pattern rewriting workloads (\autoref{chap:impact-cpython-pattern-rewriting}).
    \item A quantitative comparison of the performance of user-extensible compiler frameworks implemented in static and dynamic languages, focussing on the impact of dynamism (\autoref{chap:dynamism-pattern-rewriting}). % leveraging sidekick compilation for fine-grained analysis of the impact of dynamisms
\end{itemize}
