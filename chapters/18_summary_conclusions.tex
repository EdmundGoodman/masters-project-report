% \chapter{Evaluation}

% For any practical projects, you should almost certainly have some kind
% of evaluation, and it's often useful to separate this out into its own
% chapter.

\chapter{Conclusion}
\label{chap:conclusion}

% As you might imagine: summarizes the dissertation, and draws any
% conclusions. Depending on the length of your work, and how well you
% write, you may not need a summary here.

% You will generally want to draw some conclusions, and point to
% potential future work.

%% Summary of contributions
% Hook
% Argument
% - ``An examination of the current and best-case performance for pattern rewriting workloads in the CPython language runtime''
We present performance measurements for the implementation of user-extensible compiler frameworks in dynamic languages through the proxy of xDSL, and contrast this with a replication of existing work measuring the performance of \ac{mlir} as a proxy for static language implementations. These measurements find a $110\times$ slowdown for dynamic languages on real-world workloads, but capture the implementation details of the proxies in addition to the language runtimes (\autoref{chap:measuring-compiler-performance}).
To address this, we present specialised versions of micro-benchmarks and a pattern rewriting workload, which. This specialisation process reduces the slowdown between frameworks to $12\times$ (\autoref{chap:specialising-optimising-pattern-rewriting}).
% - ``A tool to examine CPython bytecode dispatch in program runs, facilitating the analysis of costs incurred by dynamism''
This effort revealed a gap in the tooling provision for highly granular profiling of Python code, leading to our development of ByteSight, a native tracing performance profiler for Python bytecode (\autoref{chap:profiling-bytecode}). ByteSight facilitates developing specialised implementations, and provides insights into the performance impact of dynamism on individual bytecode instructions.
% - ``An exploration of optimisation techniques to shrink the performance gap between dynamic and static languages for pattern rewriting workloads''
Using this tool, we examine optimisation techniques for dynamic language runtimes such as instruction specialisation and \ac{jit} compilation, comparing their impact between highly dynamic compiler frameworks with Python's representative suite of real-world workloads. We find that dynamic workloads exacerbate the impact of these optimisations, with instruction specialisation yielding a $10\%$ greater speedup of dynamic over static workloads. This further reduces the slowdown between frameworks to $10\times$ (\autoref{chap:impact-cpython-pattern-rewriting}).
% - ``A quantitative comparison of the performance of user-extensible compiler frameworks implemented in static and dynamic languages, focussing on the impact of dynamism''
Finally, we quantify the impact of dynamism on the performance of static and dynamic languages, elucidating the mechanism by which dynamic workloads preclude optimisations and incur overhead and justifying our earlier measurements (\autoref{chap:dynamism-pattern-rewriting}).
% Link


%% Overall summary and impact
% Hook
% Argument
Our work identifies dynamism in user-extensible compiler infrastructures as a result of the heterogeneous data structures used to represent \ac{ir}, whose structure and contents is known only at runtime. It then quantifies the performance cost this dynamism incurs in their ahead-of-time compiled implementation.
We contrast this with implementations in dynamic languages, empirically demonstrating that the performance overhead typically associated with such languages is lessened by both the workload's dynamic nature, and modern optimisation approaches to dynamic language runtimes.
This contribution challenges the status quo of implementing user-extensible compiler frameworks in static, ahead-of-time compiled languages, typified by LLVM's \ac{mlir} in C++. Instead, we motivate the use of dynamic languages for these frameworks, showing that implementations such as xDSL which follow this approach present a desirable balance of framework performance with the developer productivity required to deliver modern workloads without delay.
% Link
