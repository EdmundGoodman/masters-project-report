\chapter{Related work}
\label{chap:related-work}

% This chapter covers relevant (and typically, recent) research
% which you build upon (or improve upon). There are two complementary
% goals for this chapter:
% \begin{enumerate}
%   \item to show that you know and understand the state of the art; and
%   \item to put your work in context
% \end{enumerate}
%
% Ideally you can tackle both together by providing a critique of
% related work, and describing what is insufficient (and how you do
% better!)
%
% The related work chapter should usually come either near the front or
% near the back of the dissertation. The advantage of the former is that
% you get to build the argument for why your work is important before
% presenting your solution(s) in later chapters; the advantage of the
% latter is that don't have to forward reference to your solution too
% much. The correct choice will depend on what you're writing up, and
% your own personal preference.

%% Introduction
% Hook
% TODO: Think of a snazzy topic sentence
% Argument
In this section, we discuss existing bodies of work underpinning our thesis, and identify research gaps which our contributions aim to fill.
% Link


\section{User-extensible compiler framework performance}
\label{sec:perf-user-extensible-frameworks}

%% General vibe of the community?
% Hook
While compiler designers naturally focus on optimizing the performance of compiled code, the execution time of the compiler itself (henceforth referred to as compiler performance) also has a significant impact on developer productivity.
% Argument
For very large projects such as Firefox, which contains over twenty million lines of code \cite{bastienabadieEngineeringCodeQuality}, small changes to compiler performance can result in minutes gained or lost for each compilation -- significantly impacting developer productivity. Although there has been considerable engineering effort devoted to compiler performance, academic research continues to focus primarily on improving the compiled output rather than the compilation process itself.
% Link
As such, researchers have not yet fully explored the field, with only a few academic studies examining the performance of compiler frameworks, the most salient of which we discuss below.

%% Performance of LLVM
% Hook
Lattner and Adve's original paper proposing LLVM contains a short evaluation of the framework's performance \cite[Section 4.1.4]{lattnerLLVMCompilationFramework2004}.
% Argument
In this evaluation, the authors compare the runtime of individual transformation passes against \texttt{gcc} optimisation level \texttt{-O3} across a variety of workloads.
The results of this experiment \cite[Table 2]{lattnerLLVMCompilationFramework2004} report each of LLVM's transformation passes is at least two orders of magnitude faster than \texttt{gcc}'s end-to-end compilation across the tested workloads. This demonstrates that analysis and transformations can be performed efficiently, but has a critical flaw. By using end-to-end compilation time for \texttt{gcc}, the measurement includes time taken by non-transformation phases such as parsing, printing, and code generation, making it incomparable with the measurements of the transformation passes only for LLVM.
Furthermore, since the paper's publication twenty years ago, LLVM has evolved significantly. This evolution brings new complexity, new performance enhancements, and even new frameworks such as \ac{mlir} -- changing the calculus of its performance characteristics.
% Link
This motivated later research to re-examine these performance characteristics of compiler frameworks.

%% How slow is MLIR?
% Hook
At the 2024 European LLVM Developers' Meeting, Mehdi Amini and Jeff Nui presented their keynote talk ``How Slow is MLIR?'' \cite{aminiHowSlowMLIR2024}.
% Argument
This talk aimed to quantify the feeling in the LLVM community that \ac{mlir} incurred a significant performance cost over LLVM alone, and produce metrics against which \ac{mlir} could be optimised.
The presenters first discuss the implementation details of \ac{mlir}, including the design choices made to match common workloads.
Next, they provide a set of micro-benchmarks for key functionality provided by \ac{mlir}, along with traditional benchmarks for constant folding and loop unrolling workloads. For the micro-benchmarks and constant folding workloads, \ac{mlir} is approximately four times slower than traditional LLVM. However, \ac{mlir}'s more expressive \ac{ir} representation yields an eighty-eight times speed up over LLVM for loop unrolling.
% Link
While these results provides valuable insights into \ac{mlir}'s performance characteristics, further research is needed to fully understand the trade-offs between expressiveness and efficiency.

%% General compiler performance
% Hook
In addition to performance measurements of the LLVM \ac{mlir} framework specifically, there is a body of research examining the performance of compilers more generally.
% Argument
In their 2024 paper, Engelke and Schwarz compare compile-times across frameworks for query compilation \cite{engelkeCompileTimeAnalysisCompiler2024}, finding Cranelift's \cite{bytecodeallianceCranelift} non-pointer chasing data structures yield a $20-35\%$ speedup over LLVM, supporting our hypothesis on the performance impact of dynamism. Engelke's earlier work also touches on compiler performance, proposing low-overhead approaches to binary instrumentation \cite{engelkeInstrewLeveragingLLVM2020}, rewriting at runtime \cite{engelkeUsingLLVMOptimized2017}, and \ac{jit} compilation \cite{schwarzTPDEFastAdaptable2025} \cite{drescherFastTemplateBasedCode2024}.
% Link
However, this body of research is much smaller in volume than the literature examining the performance of compiler generated code, despite its critical importance for developer productivity.


%% Lack of other works/our differentiation
% Hook
Our work differentiates itself from this existing research in two ways.
% Argument
Firstly, the above work focusses only on the performance characteristics of popular frameworks including LLVM, \ac{mlir}, and Cranelift. We extend this to also examine xDSL's performance.
Secondly, having performance measurements and instrumentation for both \ac{mlir} and xDSL, we further extend the domain by contrasting the two frameworks through the lens of dynamism and its impact on performance.
% Link




\section{Python language performance}
\label{sec:python-performance}

%% Introduction
% Hook
Driven by Python's immense popularity, significant research effort has been expended developing tools and techniques to characterise its performance.
% Argument
% Link
This section discusses a relevant subset of these tools and techniques, and contrasts them with our novel contributions.


\subsection{Measuring application performance in Python}
\label{sec:python-performance-application}

%% Difficulty measuring python
% Hook
Reliable and accurate performance measurement is notoriously difficult.
As such, its careful execution constitutes the main contribution of systems papers and theses \cite{crapeperformance} \cite{harris2021understanding}.
% Argument
This difficulty comes from both sides of the hardware-software interface.
For example, hardware optimisations such as hierarchical caches, branch predictors, and power management schemes exhibit complex emergent behaviour \cite{hennessyComputerArchitectureQuantitative2012}, making performance measurements less predictable and consistent. Similar confounding effects come from software, from process scheduling in the operating system to garbage collection in language runtimes \cite{blackburnMythsRealitiesPerformance2004}.
Beyond this, advanced interpreters leverage runtime performance information for adaptive specialisation and JIT compilation, further muddling measurements. This phenomenon is explored by Barrett et al.'s ``Virtual Machine Warmup Blows Hot and Cold'' \cite{barrettVirtualMachineWarmup2017}, where interpreter virtual machine warmup is shown to be highly variable, with benchmarks taking over 2000 iterations to reach a steady state.
As such, accurate measurement of the performance characteristics of a Python program is more involved than the na\"ive approach of taking the wall time it takes to execute -- requiring additional tools and techniques to guarantee reliable results.
Fortunately, Python's strong ecosystem provides a wide variety of tools to achieve this goal, from the simple standard library \texttt{timeit} utility to the \texttt{pyperf} \cite{victorstinnerPsfPyperf2025} package, with more complex control over confounding effects such as warm-ups and CPU isolation.
% Link
Our work leverages these tools to make accurate measurements of compiler framework performance.

%% Our measurements and infrastructure
% Hook
A key contribution of our research is our application of these tools to produce robust performance measurements and analysis of the xDSL user-extensible compiler frameworks, extending and contrasting similar work for \ac{mlir}.
% Argument
In addition to the research contribution of these measurements themselves, our work further supports ongoing research using the xDSL framework by providing re-usable performance benchmarks and associated tooling to measure performance.
% Link
However, sometimes measurements with finer than end-to-end granularity are required to characterise performance properties more deeply. As such, our tooling also provides a simple user interface for applying performance profilers to these benchmarks.


\subsection{Profiling to understand Python's performance}
\label{sec:python-performance-profiling}

%% Research gap
% Hook
Existing profilers for Python typically operate at the function level.
% Argument
For example, Python's standard library provides the \texttt{profile} module, a Python-native tracing profiler, along with \texttt{cProfile}, a more performant C implementation of the same functionality \cite{pythonsoftwarefoundationPythonProfilers}. These instrument each call event, providing accurate profiling information for each evaluated function.
Beyond the standard library, profilers such as \texttt{pyinstrument} use statistical sampling rather than tracing to reduce overhead incurred by performance measurement \cite{rickerbyPyinstrument2025}.
In addition to this, the recent OSDI best paper winner ``Triangulating Python Performance Issues with SCALENE'' \cite{bergerTriangulatingPythonPerformance2023a} introduces another profiler which focusses on the \ac{ffi} boundary between C and Python, a key bottleneck for the best practice of delegating computation to fast low-level implementations.
This delegation is particularly effective for structured workloads such as linear algebra, but is less suitable for highly dynamic workloads.
% As such, profilers for pure Python are still important for these applications.
Furthermore, profiling information at a finer granularity than the function level is often needed to deeply the performance of a program.
% Link
\texttt{line\_profiler} provides this functionality to a line level \cite{robertkernPyutilsLine_profiler2025}, but this is still one level of abstraction over the increasingly complex implementation of CPython's interpreter.

%% ByteSight
% Hook
We fill this gap in the existing provision with ByteSight, a Python-native tracing performance profiler at the bytecode level.
% Argument
ByteSight extends existing work outputting and rewriting bytecode sequences \cite{0xecCodingReversingHacking2017} \cite{clementrouaultUnderstandingPythonExecution} \cite{nedbatchelderWickedHackPython2008}, providing an easily installable package with the novel capability of performance profiling individual bytecode instructions.
% Link
This contribution also unblocks other work in this thesis, facilitating close examination of specialised implementations and providing information about the performance of dynamic bytecode instructions.



\section{Dynamism in programming languages}
\label{sec:impact-dynamism-related-work}

%% Introduce mechanisms of dynamically/statically typed languages
% Hook
One common mechanism providing dynamism in programming languages is dynamic typing. This refers to programming languages where type-checking is performed at runtime, and variables can change type during the course of execution.
% Argument
In their essay ``The next 7000 programming languages'' \cite{chatleyNext7000Programming2019}, Chatley et al. discuss how the landscape of programming languages has changed since Landin's seminal 1966 paper ``The next 700 programming languages'' \cite{landinNext700Programming1966}. At the time of Landin's paper, there was already a split between dynamically typed languages such as Lisp and statically languages such as C and Algol. Lisp's runtime type checks incurred performance overhead and unexpected runtime type errors, but provided much greater expressivity and hence more productive development than static languages of the time. These trade-offs between static and dynamic languages remain much the same today, with Chatley et al. arguing that dynamically typed languages' expressivity results in ``excellent library support'', as they are better equipped to express structured data without a fixed schema.
% Link

% TODO: More citations here!!
%% Introduce other mechanisms of dynamism
% Hook
Beyond dynamic typing, there are a wide variety of other mechanisms by which programming languages can provide dynamism.
% Argument
One mechanism is runtime meta-programming, which refers to code which can introspect and manipulate its own behaviour at runtime. An example of this is monkey-patching in Python, which allows the programmatic modification of objects at runtime.
Another mechanism is late binding, which refers to resolving method calls at runtime when they are invoked, as opposed to being statically linked ahead of time. Interestingly, ahead-of-time compiled languages typically considered static such as C++ provide this dynamic behaviour in the case of polymorphism. When a method is invoked on an object in an inheritance hierarchy, the correct implementation to execute is resolved at runtime using C++'s \ac{vtable} mechanism. Driesen and H\"olzle quantify the performance overhead of this process in their paper ``The Direct Cost of Virtual Function Calls in C++'' \cite{driesenDirectCostVirtual1996}, measuring both a direct cost as a result of the \ac{vtable} indirection, and an indirect cost from precluded optimisation opportunities.
% Link
This shows that the dynamic aspects of languages influence the details of their implementation, and the degree to which they can be optimised.

%% Optimisation opportunities in dynamic and static languages
% Hook
Ahead-of-time compilers rely on static mechanisms such as data-flow analysis to find valid optimisations.
% Argument
As they are run ahead of time, these static analyses have less information to reason about the dynamic runtime behaviour. In this dynamic case, some traditional optimisations cannot be guaranteed to be correct, and hence cannot be leveraged to improve program performance. For example, a function which is dynamically dispatched at runtime cannot be optimised through the code motion optimisation of function inlining, as the implementation which will be invoked is not known ahead of time.
Earlier work aims to address this, for example H\"olze and Ungar's paper ``Optimizing dynamically-dispatched calls with run-time type feedback'' \cite{holzleOptimizingDynamicallydispatchedCalls1994}. The authors provide an experimental compiler implementing ``type feedback'', a profile-guided optimisation which inlines dynamically dispatched calls in object-orientated languages.
However, such approaches are specific to individual aspects of the language runtime, and being ahead of time can only optimise for a prediction of the runtime behaviour.
% Link
Furthermore, runtime behaviour may differ significantly across inputs for some workloads, making this prediction less representative of real-world behaviour.


%% Lack of other works/our differentiation
% Hook
Our work applies this body of research to understand the impact of dynamic language features on the performance of dynamic workloads.
% Argument
% Link
