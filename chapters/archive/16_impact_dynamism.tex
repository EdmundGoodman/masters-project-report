% %% Introduction
% %
% % Hook
% Having quantified the performance impact of causes of dynamism in static languages using synthetic examples and micro-benchmarks, we now examine its impact for pattern rewriting workloads of user-extensible compiler frameworks.
% % Argument
% %


%% Something about RTTI

%% Count up vtable invocations in C++ to argue about dynamic dispatch
% Hook


% %% Count up vtable invocations in C++ to argue about dynamic dispatch
% % Hook
% In addition to quantifying the performance of \ac{vtable} accesses, we can also estimate the number of dynamic calls made for a running workload.
% % Argument
% In the ARM instruction set, direct and indirect calls \cite{armlimitedARMCortexRSeries}
% ``Because the branch destination is PC-relative, it can be determined exactly at an early stage of the pipeline''. This means that direct calls are more performant, and as such efficient compilers only use indirect calls where address information is not known ahead of time: dynamic control flow.
% Using the DynamoRIO tool
% ./DynamoRIO-Linux-11.90.20236/bin64/drrun -c ./DynamoRIO-Linux-11.90.20236/samples/bin64/libcountcalls.so -- ./llvm-project-benchmarks/build/tools/mlir/unittests/Benchmarks/MLIR_IR_Benchmark --benchmark_filter=runtimePolymorphicPointerCall
% Dynamism/runtimePolymorphicPointerCall/10           136 ns          136 ns      5066864
% Dynamism/runtimePolymorphicPointerCall/64           853 ns          853 ns       821599
% Dynamism/runtimePolymorphicPointerCall/512         6793 ns         6793 ns       101941
% Dynamism/runtimePolymorphicPointerCall/4096       54938 ns        54933 ns        12526
% Dynamism/runtimePolymorphicPointerCall/10000     136118 ns       136109 ns         5134
% Dynamism/runtimePolymorphicPointerCall_BigO       13.58 N         13.58 N
% Dynamism/runtimePolymorphicPointerCall_RMS            1 %             1 %
% Thread 9507 exited - Instrumentation results:
%   saw 177100 direct calls
%   saw 297673368 indirect calls
%   saw 297850463 returns

% Instrumentation results:
%   saw 177100 direct calls
%   saw 297673368 indirect calls
%   saw 297850463 returns

% ./DynamoRIO-Linux-11.90.20236/bin64/drrun -c ./DynamoRIO-Linux-11.90.20236/samples/bin64/libcountcalls.so -- ./llvm-project-benchmarks/build/tools/mlir/unittests/Benchmarks/MLIR_IR_Benchmark --benchmark_filter=regularCallNoinline
% Dynamism/regularCallNoinline/10           123 ns          123 ns      5656394
% Dynamism/regularCallNoinline/64           790 ns          790 ns       886599
% Dynamism/regularCallNoinline/512         6313 ns         6312 ns       110701
% Dynamism/regularCallNoinline/4096       50578 ns        50572 ns        13703
% Dynamism/regularCallNoinline/10000     123394 ns       123389 ns         5678
% Dynamism/regularCallNoinline_BigO       12.34 N         12.34 N
% Dynamism/regularCallNoinline_RMS            0 %             0 %
% Thread 9508 exited - Instrumentation results:
%   saw 322640955 direct calls
%   saw 10352 indirect calls
%   saw 322651302 returns
% Instrumentation results:
%   saw 322640955 direct calls
%   saw 10352 indirect calls
%   saw 322651302 returns


% ./DynamoRIO-Linux-11.90.20236/bin64/drrun -c ./DynamoRIO-Linux-11.90.20236/samples/bin64/libcountcalls.so -- ./llvm-project-benchmarks/build/tools/mlir/unittests/Benchmarks/MLIR_IR_Benchmark --benchmark_filter=SimpleConstantFolding
% Thread 9571 exited - Instrumentation results:
%   saw 87800889 direct calls
%   saw 9226759 indirect calls
%   saw 97027643 returns

% Instrumentation results:
%   saw 87800889 direct calls
%   saw 9226759 indirect calls
%   saw 97027643 returns

%% Estimate lower bound for cost of dynamism

%% Summary

















% \chapter{Dynamism's impact on pattern rewriting in static and dynamic languages}
% \chaper{Dynamism and pattern rewriting in static and dynamic languages}
% \chapter{Understanding dynamism for pattern rewriting in xDSL and MLIR}
\chapter{Examining the impact of dynamism on pattern rewriting in static and dynamic languages}
\label{chap:dynamism-pattern-rewriting}


% A key difference between the Python and C++ runtimes is their degree of dynamism.
% \ac{mlir}'s C++ runtime incurs overhead when dynamically dispatching functions (Label \texttt{(3)} of \autoref{fig:narrative}), which is worsened by prohibiting ahead-of-time performance optimisations. In contrast, almost every bytecode operation evaluated by the Python interpreter is dynamic, each incurring an overhead.
% As such, we expect the difference in performance between language runtimes (Label \texttt{(4)} of \autoref{fig:narrative}) to be smaller for more dynamic workloads.
% To corroborate this, we measure the difference in performance between pattern rewriting workloads using xDSL and \ac{mlir}, and assess the contribution of overheads incurred by dynamism.


% Hook
% Argument
% Link







% \section{Quantifying the performance cost of dynamism in static languages}
% % Hook
% Having specialised our micro-benchmarks of xDSL to the most minimal implementation which expresses the desired functionality (\autoref{chap:specialising-optimising-pattern-rewriting}), we can use them to draw comparisons between equivalent \ac{mlir} benchmarks. This allows us to minimise the impact of implementation details, instead measuring the effect of the language runtime on each framework's performance.
% % Argument
% Of these micro-benchmarks, operation trait checking is particularly suitable for detailed analysis. This is because both implementations (Listing \ref{listing:ubenchmark-trait-checks-both}) share the same underlying algorithm: iteration over an operations traits, checking the \ac{rtti} of each one.
% % Link
% We discuss two notable sources of performance overhead incurred by dynamism in this workload: dynamically dispatching function calls; and checking \ac{rtti} of polymorphic objects. % + object access

% Hook
Dynamism affects performance through a wide variety of mechanisms, in both Python and C++.
% Argument
% Link
In this section, we examine and quantify the impact of some of these mechanisms, substantiating the argument that ...

\subsection{Cost of dynamic dispatch}

% What is dynamic dispatch and how does it work in C++

% %% How do vtables work and CPython stuff work
% % Hook
% For the common example of method polymorphism, C++ uses a \ac{vtable} to support dynamic dispatch.
% % Argument
% When a virtual function is called on an object, the compiler resolves the address of that function by following an associated pointer to its \ac{vtable}. It then indexes into this data structure to retrieve the function address, which it can then execute. This indirection allows runtime information to be used to resolve the function address, but incurs a small overhead of a pointer dereference.
% In Python, this indirection is present irrespective of whether the function address could be inferred ahead of time. Python objects have a \mintinline{text}{__dict__} mapping storing both their methods and attributes. Similarly to the \ac{vtable}, this is indexed to retrieve the function address at runtime. If the name is not found, the interpreter checks the mapping for each of its parents in the inheritance hierarchy according to its method resolution order. This approach supports dynamic behaviour such as runtime meta-programming, but incurs a higher performance cost than C++.
% % Link
% We can quantify the performance overhead of this \ac{vtable} mechanism through a synthetic example.

% How can we measure this?

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.45\textwidth}
       \centering
        \begin{minted}[fontsize=\scriptsize,escapeinside=££]{text}
class Base {
public:
    inline int inlineFunction(int a, int b) {
        return a + b;
    }
    static int staticFunction(int a, int b) {
        return a + b;
    }
    virtual int virtualFunction(int a, int b) {
        return a + b;
    }
    int regularFunction(int a, int b) {
        return a + b;
    }
    virtual ~Base() = default;
};

class Derived : public Base {
public:
    int virtualFunction(int a, int b) override {
        return a + b;
    }
};
        \end{minted}
        \captionsetup{name=Listing}
        \caption{.}
        \label{listing:}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.5\textwidth}
        \centering
        \begin{minted}[breakanywhere,fontsize=\scriptsize,escapeinside=££]{text}
void go() {
    // Setup
    int a = 5;
    int b = 7;
    int result = 0;
    Base baseObj;
    Derived derivedObj;
    Base* monomorphicPtr = &baseObj;
    Base* polymorphicPtr = &derivedObj;

    // Examples
    result = a + b;
    result = baseObj.inlineFunction(a, b);
    result = Base::staticFunction(a, b);
    result = baseObj.regularFunction(a, b);
    result = baseObj.virtualFunction(a, b);
    result = derivedObj.virtualFunction(a, b);
    result = monomorphicPtr->virtualFunction(a, b);
    result = polymorphicPtr->virtualFunction(a, b);
}
        \end{minted}
        \captionsetup{name=Listing}
        \caption{.}
        \label{listing:}
    \end{subfigure}
    \vspace{1em}
    \captionsetup{name=Listing}
    \caption{.}
    \label{listing:}
\end{figure}

% What are our measurement results? How does this quantify performance in dyunamism?

\begin{table}[H]
  \caption{.}
  \label{tab:dynamic-dispatch-perf}
  \centering
  \begin{tabular}{lllc}
    \toprule
    \multicolumn{3}{c}{\textbf{Function}} \\
    \cmidrule(r){1-3}
    \textbf{Specifier} & \textbf{Morphism} & \textbf{Indirection} & \textbf{Duration [ns]} \\
    % \textbf{Invocation type} & \textbf{Duration [ns]} \\
    \midrule
    Default & Monomorphic & Direct & $0.614$ \\
    Inline & Monomorphic & Direct & $0.614$ \\
    Static & Monomorphic & Direct & $0.613$ \\
    Virtual & Monomorphic & Direct & $0.613$ \\
    Virtual & Polymorphic & Direct & $1.07$ \\
    Virtual & Monomorphic & Pointer & $1.98$ \\
    Virtual & Polymorphic & Pointer & $1.90$ \\
    % Function & $0.614$ \\
    % Inline function & $0.614$ \\
    % Static function & $0.613$ \\
    % Monomorphic virtual function & $0.613$ \\
    % Polymorphic virtual function & $1.07$ \\
    % Indirect monomorphic virtual function & $1.98$ \\
    % Indirect polymorphic virtual function & $1.9$ \\
    \bottomrule
  \end{tabular}
\end{table}



\subsection{Dynamism hiding ahead-of-time optimisations}



\subsection{Runtime type information}

%% C++ RTTI vs LLVM RTTI

%% Python RTTI

% How can we measure this?


% What are our measurement results? How does this quantify performance in dyunamism?






% \subsection{Specialised and unspecialised instructions}

% % Hook
% As discussed in \autoref{sec:specialising-adaptive-interpreter}, Python's specialising adaptive interpreter
% % Argument
% % Link
% In contrast to the previous examples where introducing more dynamism hinders performance, this is an example of where removing dynamism can result in performance improvements.

% % Specialist something something.....






\section{Dynamism in xDSL}

% Hook
% Argument
% Link

\subsection{Operation trait checks}

% Hook
Having specialised xDSL's \mintinline{python}{has_trait} method to the most minimal implementation which expresses the desired functionality, we can draw comparisons between equivalent algorithms which predominantly measure the effect of the language runtime.
% Argument
Both implementations (Listing \ref{listing:ubenchmark-trait-checks-both}) share the same underlying algorithm: iteration over an operations traits, checking against each one. However, the mechanism used for this algorithm differs significantly between xDSL and MLIR.
By leveraging Python's dynamic nature, xDSL can invoke the \mintinline{python}{isinstance} function to check each trait. In contrast, MLIR uses template metaprogramming instead of the class hierarchy to define traits. This depends on \mintinline{c++}{TypeID}\footnote{\scriptsize{\url{https://mlir.llvm.org/doxygen/TypeID_8h_source.html}}}, a custom data structure to encode dynamic \ac{rtti} in C++.
% TODO: Does this need more detail?
Whilst this implementation incurs complexity (\autoref{fig:ubenchmark-hastrait-dynamism}), it remains performant, as the \mintinline{c++}{TypeID} data structure is constructed to remedy many of the issues of native C++ \ac{rtti}.
% Link
However, this dynamism impacts performance beyond just the runtime of the individual function, as it presents an optimisation boundary -- precluding other optimisations which could be applied if the result could be inferred at compile time. % TODO: This really needs to be substantiated somehow, but perhaps not here?

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{\textwidth}
        \includegraphics[width=\textwidth]{images/impact_dynamism/hastrait_xdsl_viztracer_optimised.png}
        \caption{\texttt{viztracer} trace of xDSL's optimised \mintinline{python}{has_trait} implementation.}
        \label{fig:ubenchmark-hastrait-xdsl-viztracer-optimised}
    \end{subfigure}
    \begin{subfigure}[b]{\textwidth}
        \includegraphics[width=\textwidth]{images/impact_dynamism/hastrait_mlir_samply.png}
        \caption{\texttt{samply} trace of MLIR's \mintinline{c++}{has_trait} method.}
        \label{fig:ubenchmark-hastrait-mlir-samply}
    \end{subfigure}
    \caption{MLIR's dynamic trait checking using C++ RTTI is more complex than xDSL's Python implementation using \mintinline{python}{isinstance}.}
    \label{fig:ubenchmark-hastrait-dynamism}
\end{figure}


% \subsection{Constant folding}

% Hook
% Argument
% Link

% Hook
% Argument
% Link

% Hook
% Argument
% Link


\section{Summary}

% Hook
% Argument
% Link

% Hook
% Argument
% Link













%  =========================================================================
%  =========================================================================
%  =========================================================================

% \section{Quantifying the performance impact of dynamism in language runtimes}
% \label{sec:dynamism-pattern-rewriting-quantifying}

% \subsection{Cost of dynamic dispatch}
% \label{sec:dynamism-pattern-rewriting-dispatch}

% \subsubsection{C++ vTables}
% \label{sec:dynamism-pattern-rewriting-vtables}

% \subsubsection{Optimisation boundaries}
% \label{sec:dynamism-pattern-rewriting-boundaries}

% \subsection{Runtime type information}
% \label{sec:dynamism-pattern-rewriting-rtti}



% \section{Dynamism in user-extensible compiler-frameworks}
% \label{sec:dynamism-pattern-rewriting-framework}

% % Hook
% % Argument
% % Link

% \subsection{Operation trait checks}
% \label{sec:dynamism-pattern-rewriting-operation-trait}

% %% Where is the dynamism?
% % Hook
% % Argument
% % Link

% %% How does it impact performance?
% % Hook
% % Argument
% % Link

% \subsection{Constant folding}
% \label{sec:dynamism-pattern-rewriting-constant-folding}

% %% Where is the dynamism?
% % Hook
% % Argument
% % Link

% %% How does it impact performance?
% % Hook
% % Argument
% % Link


% \section{Summary}
% \label{sec:dynamism-pattern-rewriting-summary}



%  =========================================================================
%  =========================================================================
%  =========================================================================














% \chapter{Examining the impact of dynamism on pattern rewriting in static and dynamic languages}
% \label{chap:dynamism-pattern-rewriting}

% % Hook
% % Argument
% % Link

% \section{Quantifying the performance impact of dynamism in language runtimes}

% % Hook
% % Argument
% % Link

% % TODO: Could unmerge C++ and Python?
% \subsection{Dynamism in C++}

% % Hook
% % Argument
% % Link

% \subsection{Cost of dynamic dispatch}

% %% Introduce vtables etc.
% % Hook
% % Argument
% % Link

% %% Perf table/graph

% %% Empirical performance of vtables vs static calls
% % Hook
% % Argument
% % Link

% \subsection{Dynamism hiding ahead-of-time optimisations}

% %% Introduce common optimisations
% % Hook
% % Argument
% % Link

% %% How can we construct an experiment to show these being hidden?
% % Hook
% % Argument
% % Link

% %% Perf table/graph

% %% Discussion of results
% % Hook
% % Argument
% % Link

% \subsection{Runtime type information}

% %% Introduce RTTI machinery
% % Hook
% % Argument
% % Link

% %% How can we construct an experiment to show these?
% % Hook
% % Argument
% % Link

% %% Perf table/graph

% %% Discussion of results
% % Hook
% % Argument
% % Link



% \subsection{Dynamism in Python}

% % Hook
% % Argument
% % Link

% \subsection{Specialised and unspecialised instructions}

% % Hook
% % Argument
% % Link

% %% Perf table/graph

% %% Discussion of results
% % Hook
% % Argument
% % Link

% \subsection{Runtime type information}
% % Hook
% % Argument
% % Link

% %% Perf table/graph

% %% Discussion of results
% % Hook
% % Argument
% % Link






% \section{Dynamism in xDSL}

% % Hook
% % Argument
% % Link

% \subsection{Operation trait checks}

% % Hook
% Having specialised xDSL's \mintinline{python}{has_trait} method to the most minimal implementation which expresses the desired functionality, we can draw comparisons between equivalent algorithms which predominantly measure the effect of the language runtime.
% % Argument
% Both implementations (Listing \ref{listing:ubenchmark-trait-checks-both}) share the same underlying algorithm: iteration over an operations traits, checking against each one. However, the mechanism used for this algorithm differs significantly between xDSL and MLIR.
% By leveraging Python's dynamic nature, xDSL can invoke the \mintinline{python}{isinstance} function to check each trait. In contrast, MLIR uses template metaprogramming instead of the class hierarchy to define traits. This depends on \mintinline{c++}{TypeID}\footnote{\url{https://mlir.llvm.org/doxygen/TypeID_8h_source.html}}, a custom data structure to encode dynamic \ac{rtti} in C++.
% % TODO: Does this need more detail?
% Whilst this implementation incurs complexity (\autoref{fig:ubenchmark-hastrait-dynamism}), it remains performant, as the \mintinline{c++}{TypeID} data structure is constructed to remedy many of the issues of native C++ \ac{rtti}.
% % Link
% However, this dynamism impacts performance beyond just the runtime of the individual function, as it presents an optimisation boundary -- precluding other optimisations which could be applied if the result could be inferred at compile time. % TODO: This really needs to be substantiated somehow, but perhaps not here?

% \begin{figure}[H]
%     \centering
%     \begin{subfigure}[b]{\textwidth}
%         \includegraphics[width=\textwidth]{images/impact_dynamism/hastrait_xdsl_viztracer_optimised.png}
%         \caption{\texttt{viztracer} trace of xDSL's optimised \mintinline{python}{has_trait} implementation.}
%         \label{fig:ubenchmark-hastrait-xdsl-viztracer-optimised}
%     \end{subfigure}
%     \begin{subfigure}[b]{\textwidth}
%         \includegraphics[width=\textwidth]{images/impact_dynamism/hastrait_mlir_samply.png}
%         \caption{\texttt{samply} trace of MLIR's \mintinline{c++}{has_trait} method.}
%         \label{fig:ubenchmark-hastrait-mlir-samply}
%     \end{subfigure}
%     \caption{MLIR's dynamic trait checking using C++ RTTI is more complex than xDSL's Python implementation using \mintinline{python}{isinstance}.}
%     \label{fig:ubenchmark-hastrait-dynamism}
% \end{figure}


% \subsection{Constant folding}

% % Hook
% % Argument
% % Link

% % Hook
% % Argument
% % Link

% % Hook
% % Argument
% % Link


% \section{Summary}

% % Hook
% % Argument
% % Link

% % Hook
% % Argument
% % Link
